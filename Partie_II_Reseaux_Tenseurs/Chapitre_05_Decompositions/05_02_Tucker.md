# 5.2 D√©composition Tucker

---

## Introduction

La **d√©composition Tucker** (aussi appel√©e Higher-Order SVD - HOSVD) factorise un tenseur en un tenseur noyau et des matrices facteurs pour chaque mode. Elle est plus flexible que CP mais le noyau peut √™tre grand.

---

## D√©finition Formelle

Pour un tenseur $\mathcal{T} \in \mathbb{R}^{I_1 \times I_2 \times \cdots \times I_N}$, la d√©composition Tucker est :

$$\mathcal{T} \approx \mathcal{G} \times_1 \mathbf{U}^{(1)} \times_2 \mathbf{U}^{(2)} \times_3 \cdots \times_N \mathbf{U}^{(N)}$$

o√π :
- $\mathcal{G} \in \mathbb{R}^{R_1 \times R_2 \times \cdots \times R_N}$ : tenseur noyau (core tensor)
- $\mathbf{U}^{(n)} \in \mathbb{R}^{I_n \times R_n}$ : matrice facteur du mode $n$
- $\times_n$ : produit mode-$n$

---

## Propri√©t√©s

```python
import numpy as np

class TuckerDecomposition:
    """
    D√©composition Tucker d'un tenseur
    """
    
    def __init__(self, tensor, ranks):
        """
        Args:
            tensor: Tenseur √† d√©composer
            ranks: tuple (R‚ÇÅ, R‚ÇÇ, ..., R‚Çô) - rangs par mode
        """
        self.tensor = np.array(tensor)
        self.ranks = ranks
        self.n_modes = tensor.ndim
        self.shape = tensor.shape
        
        # Noyau et facteurs (initialis√©s plus tard)
        self.core = None
        self.factors = None
    
    def reconstruct(self):
        """
        Reconstruit le tenseur: G √ó‚ÇÅ U‚ÇÅ √ó‚ÇÇ U‚ÇÇ √ó‚ÇÉ ...
        """
        result = self.core.copy()
        
        for mode, factor in enumerate(self.factors):
            result = mode_n_product(result, factor, mode)
        
        return result
    
    def compression_ratio(self):
        """Calcule le ratio de compression"""
        original_size = np.prod(self.shape)
        
        core_size = np.prod(self.core.shape)
        factors_size = sum(f.shape[0] * f.shape[1] for f in self.factors)
        
        compressed_size = core_size + factors_size
        return original_size / compressed_size

def mode_n_product(tensor, matrix, mode):
    """
    Produit mode-n : T √ó‚Çô M
    
    Args:
        tensor: Tenseur (I‚ÇÅ, ..., I‚Çô, ..., I_N)
        matrix: Matrice (J, I‚Çô)
        mode: Mode sur lequel contracter
    """
    # D√©place le mode en premi√®re position
    tensor = np.moveaxis(tensor, mode, 0)
    
    # Reshape pour multiplication matricielle
    original_shape = tensor.shape
    tensor = tensor.reshape(original_shape[0], -1)
    
    # Multiplication: M @ tensor
    result = matrix @ tensor
    
    # Nouvelle shape
    new_shape = (matrix.shape[0],) + original_shape[1:]
    result = result.reshape(new_shape)
    
    # Remet le mode √† sa place originale
    result = np.moveaxis(result, 0, mode)
    
    return result
```

---

## HOSVD (Higher-Order SVD)

```python
def hosvd(tensor, ranks=None, full=False):
    """
    Higher-Order SVD: m√©thode standard pour la d√©composition Tucker
    
    Algorithm:
    1. Pour chaque mode n:
       - Matricise selon le mode n
       - Fait SVD
       - Garde les R_n premi√®res composantes
    2. Calcule le noyau via projection
    """
    shape = tensor.shape
    n_modes = len(shape)
    
    if ranks is None:
        ranks = shape  # Pas de compression
    
    # SVD de chaque mode
    factors = []
    for mode in range(n_modes):
        # Matricisation
        tensor_mat = unfold_tensor(tensor, mode)
        
        # SVD
        U, S, Vt = np.linalg.svd(tensor_mat, full_matrices=False)
        
        # Garde les R_n premi√®res colonnes
        rank = ranks[mode]
        if full:
            rank = min(rank, len(S))
        
        factors.append(U[:, :rank])
    
    # Calcule le noyau
    core = tensor.copy()
    for mode, factor in enumerate(factors):
        # Projection: G = T √ó‚ÇÅ U‚ÇÅ^T √ó‚ÇÇ U‚ÇÇ^T √ó‚ÇÉ ...
        core = mode_n_product(core, factor.T, mode)
    
    return core, factors

# Exemple
tensor = np.random.randn(10, 12, 8)
ranks = (5, 6, 4)  # Rangs r√©duits

core, factors = hosvd(tensor, ranks)

print(f"D√©composition Tucker:")
print(f"  Tenseur original: {tensor.shape}")
print(f"  Noyau: {core.shape}")
print(f"  Facteurs: {[f.shape for f in factors]}")

# Reconstruction
tucker = TuckerDecomposition(tensor, ranks)
tucker.core = core
tucker.factors = factors

reconstructed = tucker.reconstruct()
error = np.linalg.norm(tensor - reconstructed, 'fro') / np.linalg.norm(tensor, 'fro')
print(f"  Erreur relative: {error:.6f}")
print(f"  Compression: {tucker.compression_ratio():.2f}x")
```

---

## HOOI (Higher-Order Orthogonal Iteration)

```python
def hooi(tensor, ranks, max_iter=100, tol=1e-6):
    """
    Higher-Order Orthogonal Iteration
    
    It√©ratif, meilleur que HOSVD pour la compression
    """
    n_modes = len(tensor.shape)
    
    # Initialisation avec HOSVD
    core, factors = hosvd(tensor, ranks, full=False)
    
    prev_error = float('inf')
    
    for iteration in range(max_iter):
        # Mise √† jour it√©rative de chaque facteur
        for mode in range(n_modes):
            # Contracte tous les autres modes
            temp = tensor.copy()
            for n in range(n_modes):
                if n != mode:
                    temp = mode_n_product(temp, factors[n].T, n)
            
            # Matricise selon le mode
            temp_mat = unfold_tensor(temp, mode)
            
            # SVD pour trouver le meilleur facteur
            U, S, Vt = np.linalg.svd(temp_mat, full_matrices=False)
            factors[mode] = U[:, :ranks[mode]]
        
        # Recalcule le noyau
        core = tensor.copy()
        for mode, factor in enumerate(factors):
            core = mode_n_product(core, factor.T, mode)
        
        # Calcule l'erreur
        reconstructed = reconstruct_tucker(core, factors)
        error = np.linalg.norm(tensor - reconstructed, 'fro')
        rel_error = error / np.linalg.norm(tensor, 'fro')
        
        if iteration % 10 == 0:
            print(f"Iteration {iteration}: Error = {rel_error:.6f}")
        
        if abs(prev_error - error) < tol:
            print(f"Converged after {iteration+1} iterations")
            break
        
        prev_error = error
    
    return core, factors, rel_error

def reconstruct_tucker(core, factors):
    """Reconstruit depuis la d√©composition Tucker"""
    result = core.copy()
    for mode, factor in enumerate(factors):
        result = mode_n_product(result, factor, mode)
    return result

# Comparaison HOSVD vs HOOI
tensor = np.random.randn(15, 20, 10)
ranks = (8, 10, 5)

print("Comparaison HOSVD vs HOOI:")
core_hosvd, factors_hosvd = hosvd(tensor, ranks)
recon_hosvd = reconstruct_tucker(core_hosvd, factors_hosvd)
error_hosvd = np.linalg.norm(tensor - recon_hosvd, 'fro') / np.linalg.norm(tensor, 'fro')

core_hooi, factors_hooi, error_hooi = hooi(tensor, ranks, max_iter=50)

print(f"  HOSVD error: {error_hosvd:.6f}")
print(f"  HOOI error: {error_hooi:.6f}")
print(f"  Am√©lioration: {(error_hosvd - error_hooi) / error_hosvd * 100:.1f}%")
```

---

## Relation avec CP

### CP comme Tucker D√©compos√©

CP est un cas sp√©cial de Tucker o√π le noyau est super-diagonal :

```python
def tucker_to_cp(core, factors):
    """
    Convertit une d√©composition Tucker en CP (si possible)
    
    N√©cessite que le noyau soit super-diagonal
    """
    # V√©rifie si le noyau est super-diagonal
    # (uniquement des valeurs non-nulles sur la diagonale principale)
    
    # Extraction des facteurs CP depuis Tucker
    # (Simplification)
    pass

def cp_to_tucker(cp_factors, cp_weights):
    """
    Convertit CP en Tucker (toujours possible)
    
    Le noyau Tucker est super-diagonal avec les poids CP
    """
    n_modes = len(cp_factors)
    rank = cp_factors[0].shape[1]
    
    # Cr√©e le noyau super-diagonal
    core = np.zeros([f.shape[1] for f in cp_factors])
    for r in range(rank):
        indices = tuple([r] * n_modes)
        core[indices] = cp_weights[r]
    
    return core, cp_factors
```

---

## Applications en Compression

### Compression de Tenseurs de Poids

```python
class TuckerCompressedConv(nn.Module):
    """
    Couche convolutionnelle compress√©e avec Tucker
    """
    
    def __init__(self, in_channels, out_channels, kernel_size, 
                 ranks=(None, None, None, None)):
        super().__init__()
        
        # Tucker pour les poids 4D: (out_ch, in_ch, kH, kW)
        if ranks[0] is None:
            ranks = (out_channels, in_channels, kernel_size, kernel_size)
        
        self.ranks = ranks
        
        # Noyau Tucker
        self.core = nn.Parameter(
            torch.randn(*ranks)
        )
        
        # Facteurs (un par mode)
        self.factor_out = nn.Parameter(torch.randn(out_channels, ranks[0]))
        self.factor_in = nn.Parameter(torch.randn(in_channels, ranks[1]))
        self.factor_h = nn.Parameter(torch.randn(kernel_size, ranks[2]))
        self.factor_w = nn.Parameter(torch.randn(kernel_size, ranks[3]))
        
    def forward(self, x):
        """Forward avec poids reconstruits depuis Tucker"""
        # Reconstruit les poids (co√ªteux, peut √™tre pr√©-calcul√©)
        weights = self.reconstruct_weights()
        
        return F.conv2d(x, weights, stride=1, padding=1)
    
    def reconstruct_weights(self):
        """Reconstruit les poids 4D depuis la d√©composition"""
        # Contracte le noyau avec les facteurs
        weights = self.core
        
        # Mode 0: out_channels
        weights = torch.tensordot(self.factor_out, weights, dims=([1], [0]))
        
        # Mode 1: in_channels
        weights = torch.tensordot(self.factor_in, weights, dims=([1], [1]))
        
        # Mode 2: height
        weights = torch.tensordot(self.factor_h, weights, dims=([1], [2]))
        
        # Mode 3: width
        weights = torch.tensordot(self.factor_w, weights, dims=([1], [3]))
        
        return weights
    
    def compression_ratio(self):
        """Ratio de compression"""
        original = (self.factor_out.shape[0] * self.factor_in.shape[0] * 
                   self.factor_h.shape[0] * self.factor_w.shape[0])
        
        compressed = (self.core.numel() + 
                     sum([self.factor_out.numel(), self.factor_in.numel(),
                          self.factor_h.numel(), self.factor_w.numel()]))
        
        return original / compressed

# Exemple
conv_original = nn.Conv2d(64, 128, 3, padding=1)
conv_compressed = TuckerCompressedConv(64, 128, 3, ranks=(32, 32, 2, 2))

print(f"Compression Tucker pour Conv:")
print(f"  Param√®tres originaux: {conv_original.weight.numel():,}")
print(f"  Param√®tres compress√©s: {sum(p.numel() for p in conv_compressed.parameters()):,}")
print(f"  Compression: {conv_compressed.compression_ratio():.2f}x")
```

---

## Avantages et Inconv√©nients

### Avantages

- **Flexibilit√©** : Rangs diff√©rents par mode
- **Compression efficace** : Si les rangs sont bien choisis
- **Stabilit√© num√©rique** : HOSVD est stable

### Inconv√©nients

- **Taille du noyau** : Peut √™tre grand si les rangs ne sont pas bien choisis
- **Curse of dimensionality** : Le noyau a $R_1 \times R_2 \times \cdots \times R_N$ √©l√©ments

```python
def tucker_core_size(ranks):
    """Calcule la taille du noyau Tucker"""
    return np.prod(ranks)

# Exemple: curse of dimensionality
for n_modes in [3, 4, 5]:
    ranks = tuple([10] * n_modes)
    core_size = tucker_core_size(ranks)
    print(f"Noyau {n_modes}D avec rangs {ranks}: {core_size:,} √©l√©ments")
```

---

## Exercices

### Exercice 5.2.1
Comparez HOSVD et HOOI sur un tenseur de rang faible. Lequel donne la meilleure reconstruction ?

### Exercice 5.2.2
Impl√©mentez une fonction qui trouve automatiquement les rangs optimaux pour une d√©composition Tucker avec contrainte d'erreur.

### Exercice 5.2.3
Utilisez Tucker pour compresser une couche convolutionnelle 3√ó3 et mesurez la perte de performance.

---

## Points Cl√©s √† Retenir

> üìå **Tucker est plus flexible que CP mais le noyau peut √™tre grand**

> üìå **HOSVD est rapide mais HOOI donne de meilleurs r√©sultats**

> üìå **Le curse of dimensionality affecte la taille du noyau**

> üìå **Tucker est efficace pour compresser les convolutions**

---

*Section suivante : [5.3 Tensor Train / Matrix Product States](./05_03_TensorTrain.md)*

