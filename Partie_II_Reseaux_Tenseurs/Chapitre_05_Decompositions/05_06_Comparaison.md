# 5.6 Comparaison et Choix de D√©composition

---

## Introduction

Ce chapitre compare les diff√©rentes d√©compositions tensorielles et guide le choix selon l'application.

---

## Tableau Comparatif

```python
import numpy as np

def comparison_table():
    """
    Comparaison compl√®te des d√©compositions
    """
    
    decompositions = {
        'CP': {
            'Complexit√© params': 'O(N √ó I √ó R)',
            'Unicit√©': 'Sous conditions',
            'Stabilit√©': 'Moyenne (d√©g√©n√©rescence)',
            'Facilit√© calcul': 'Moyenne (ALS)',
            'Meilleur pour': 'Rang faible, interpr√©tabilit√©'
        },
        'Tucker': {
            'Complexit√© params': 'O(R^N + N √ó I √ó R)',
            'Unicit√©': 'Oui (sous orthonormalit√©)',
            'Stabilit√©': 'Bonne (HOSVD stable)',
            'Facilit√© calcul': 'Bonne (HOSVD rapide)',
            'Meilleur pour': 'Compression mod√©r√©e, flexibilit√©'
        },
        'Tensor Train': {
            'Complexit√© params': 'O(N √ó I √ó R¬≤)',
            'Unicit√©': 'Non (sauf conditions)',
            'Stabilit√©': 'Bonne',
            'Facilit√© calcul': 'Bonne (TT-SVD)',
            'Meilleur pour': 'Grandes dimensions, compression forte'
        },
        'Tensor Ring': {
            'Complexit√© params': 'O(N √ó I √ó R¬≤)',
            'Unicit√©': 'Non',
            'Stabilit√©': 'Bonne',
            'Facilit√© calcul': 'Bonne',
            'Meilleur pour': 'Rang circulaire, sym√©trie'
        }
    }
    
    print("Comparaison des D√©compositions Tensorielles")
    print("=" * 80)
    print(f"{'D√©composition':<15} | {'Complexit√©':<20} | {'Unicit√©':<10} | {'Stabilit√©':<10}")
    print("-" * 80)
    
    for name, info in decompositions.items():
        print(f"{name:<15} | {info['Complexit√© params']:<20} | "
              f"{info['Unicit√©']:<10} | {info['Stabilit√©']:<10}")
    
    return decompositions

comparison_table()
```

---

## Choix selon l'Application

### Compression de Mod√®les ML

```python
class DecompositionSelector:
    """
    S√©lectionne la meilleure d√©composition selon le cas
    """
    
    @staticmethod
    def select_for_linear_layer(in_features, out_features, target_compression):
        """
        S√©lection pour une couche lin√©aire
        """
        original_size = in_features * out_features
        
        # Teste diff√©rentes d√©compositions
        options = {}
        
        # CP (factorisation matricielle)
        cp_rank = int(np.sqrt(original_size / (in_features + out_features) / target_compression))
        cp_size = cp_rank * (in_features + out_features)
        options['CP'] = {
            'params': cp_size,
            'compression': original_size / cp_size,
            'complexity': 'O(n)'
        }
        
        # TT (si on peut factoriser les dimensions)
        # N√©cessite de factoriser in_features et out_features
        # Ex: 1024 = 32√ó32, 512 = 16√ó32
        # Simplification
        tt_rank = 8
        tt_size = estimate_tt_params([32, 32], [16, 32], tt_rank)
        options['TT'] = {
            'params': tt_size,
            'compression': original_size / tt_size,
            'complexity': 'O(d)'
        }
        
        # S√©lectionne la meilleure
        best = max(options.items(), key=lambda x: x[1]['compression'])
        
        return best[0], options
    
    @staticmethod
    def select_for_conv_layer(in_ch, out_ch, kernel_size, target_compression):
        """
        S√©lection pour une couche convolutionnelle
        """
        original_size = in_ch * out_ch * kernel_size * kernel_size
        
        # Tucker est souvent meilleur pour les convolutions
        # (structure 4D naturelle)
        tucker_ranks = estimate_tucker_ranks(
            (out_ch, in_ch, kernel_size, kernel_size),
            target_compression
        )
        
        tucker_size = estimate_tucker_params(
            (out_ch, in_ch, kernel_size, kernel_size),
            tucker_ranks
        )
        
        return 'Tucker', {
            'params': tucker_size,
            'compression': original_size / tucker_size
        }

def estimate_tt_params(input_dims, output_dims, rank):
    """Estime les param√®tres TT"""
    # Simplifi√©
    return rank * (sum(input_dims) + sum(output_dims))

def estimate_tucker_params(shape, ranks):
    """Estime les param√®tres Tucker"""
    core_size = np.prod(ranks)
    factors_size = sum(shape[i] * ranks[i] for i in range(len(shape)))
    return core_size + factors_size

def estimate_tucker_ranks(shape, target_compression):
    """Estime les rangs Tucker pour une compression cible"""
    # Heuristique simplifi√©e
    original_size = np.prod(shape)
    target_size = original_size / target_compression
    
    # Approximation: rangs uniformes
    avg_rank = int((target_size / len(shape)) ** (1/len(shape)))
    return tuple([avg_rank] * len(shape))

# Exemple
selector = DecompositionSelector()
best, options = selector.select_for_linear_layer(1024, 512, target_compression=10)
print(f"Meilleure d√©composition pour Linear(1024, 512): {best}")
print(f"Options: {options}")
```

---

## Crit√®res de S√©lection

### 1. Structure des Donn√©es

```python
def choose_by_structure(tensor_shape, data_structure):
    """
    Choisit selon la structure des donn√©es
    """
    if data_structure == 'sequential':
        # TT est naturel pour les s√©quences
        return 'Tensor Train'
    
    elif data_structure == 'hierarchical':
        # HT pour structures hi√©rarchiques
        return 'Hierarchical Tucker'
    
    elif data_structure == 'matrix_like':
        # CP ou low-rank pour matrices
        return 'CP'
    
    elif data_structure == 'multidimensional':
        # Tucker pour dimensions multiples
        return 'Tucker'
```

### 2. Contraintes de Compression

```python
def choose_by_compression_target(original_size, target_size, n_modes):
    """
    Choisit selon l'objectif de compression
    """
    compression_ratio = original_size / target_size
    
    if compression_ratio < 5:
        return 'CP'  # Compression l√©g√®re
    elif compression_ratio < 50:
        return 'Tucker'  # Compression mod√©r√©e
    else:
        return 'Tensor Train'  # Compression forte
```

### 3. Contraintes de Calcul

```python
def choose_by_compute_budget(max_params, n_modes, dim_per_mode):
    """
    Choisit selon le budget computationnel
    """
    # TT: O(N √ó I √ó R¬≤)
    # Peut contr√¥ler R pour tenir dans le budget
    
    # Tucker: O(R^N) - curse of dimensionality
    # Limit√© pour N grand
    
    if n_modes > 5:
        return 'Tensor Train'  # √âvite curse
    else:
        return 'Tucker'  # Plus flexible
```

---

## Benchmarks Empiriques

```python
def benchmark_decompositions(tensor, ranks_dict, target_error=0.01):
    """
    Benchmark les diff√©rentes d√©compositions
    """
    results = {}
    
    # CP
    try:
        cp_factors, cp_weights, cp_error = cp_als(
            tensor, ranks_dict['cp'], max_iter=50
        )
        cp_params = sum(f.size for f in cp_factors) + len(cp_weights)
        results['CP'] = {
            'error': cp_error,
            'params': cp_params,
            'meets_target': cp_error < target_error
        }
    except:
        results['CP'] = {'error': np.inf, 'params': 0}
    
    # Tucker
    try:
        tucker_core, tucker_factors = hosvd(tensor, ranks_dict['tucker'])
        tucker_error = compute_reconstruction_error(
            tensor, reconstruct_tucker(tucker_core, tucker_factors)
        )
        tucker_params = tucker_core.size + sum(f.size for f in tucker_factors)
        results['Tucker'] = {
            'error': tucker_error,
            'params': tucker_params,
            'meets_target': tucker_error < target_error
        }
    except:
        results['Tucker'] = {'error': np.inf, 'params': 0}
    
    # TT
    try:
        tt_cores = tt_svd(tensor, max_rank=ranks_dict['tt'])
        tt_error = compute_tt_error(tensor, tt_cores)
        tt_params = sum(c.size for c in tt_cores)
        results['TT'] = {
            'error': tt_error,
            'params': tt_params,
            'meets_target': tt_error < target_error
        }
    except:
        results['TT'] = {'error': np.inf, 'params': 0}
    
    return results

def compute_reconstruction_error(original, reconstructed):
    """Calcule l'erreur relative"""
    return np.linalg.norm(original - reconstructed, 'fro') / \
           np.linalg.norm(original, 'fro')

def compute_tt_error(tensor, cores):
    """Erreur pour TT"""
    tt = TensorTrain(cores)
    reconstructed = tt.reconstruct()
    return compute_reconstruction_error(tensor, reconstructed)

# Test
tensor_bench = np.random.randn(10, 12, 8)
ranks = {'cp': 5, 'tucker': (5, 6, 4), 'tt': [5, 5]}

results = benchmark_decompositions(tensor_bench, ranks)

print("\nBenchmark des d√©compositions:")
for name, res in results.items():
    print(f"  {name}:")
    print(f"    Erreur: {res.get('error', np.inf):.6f}")
    print(f"    Param√®tres: {res.get('params', 0):,}")
    print(f"    Objectif atteint: {res.get('meets_target', False)}")
```

---

## Guide de D√©cision

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Arbre de D√©cision                                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  N > 5 dimensions?                                              ‚îÇ
‚îÇ    ‚îú‚îÄ Oui ‚Üí Tensor Train (√©vite curse)                        ‚îÇ
‚îÇ    ‚îî‚îÄ Non ‚Üí Continue...                                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Compression > 50x?                                             ‚îÇ
‚îÇ    ‚îú‚îÄ Oui ‚Üí Tensor Train                                       ‚îÇ
‚îÇ    ‚îî‚îÄ Non ‚Üí Continue...                                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Structure hi√©rarchique?                                        ‚îÇ
‚îÇ    ‚îú‚îÄ Oui ‚Üí Hierarchical Tucker                                ‚îÇ
‚îÇ    ‚îî‚îÄ Non ‚Üí Continue...                                        ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  Rang faible et connu?                                          ‚îÇ
‚îÇ    ‚îú‚îÄ Oui ‚Üí CP                                                 ‚îÇ
‚îÇ    ‚îî‚îÄ Non ‚Üí Tucker                                             ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Exercices

### Exercice 5.6.1
Testez toutes les d√©compositions sur le m√™me tenseur et comparez l'erreur vs le nombre de param√®tres.

### Exercice 5.6.2
Cr√©ez un syst√®me automatique qui s√©lectionne la meilleure d√©composition selon des crit√®res (erreur, compression, vitesse).

### Exercice 5.6.3
Analysez quelle d√©composition est la meilleure pour compresser une couche ResNet.

---

## Points Cl√©s √† Retenir

> üìå **CP : Simple mais peut √™tre instable, bon pour rang faible connu**

> üìå **Tucker : Flexible mais souffre de curse of dimensionality**

> üìå **TT : Excellent pour grandes dimensions, structure s√©quentielle**

> üìå **HT : Bon compromis, structure hi√©rarchique naturelle**

> üìå **Le choix d√©pend de la structure des donn√©es et des contraintes**

---

*Chapitre suivant : [Chapitre 6 - R√©seaux de Tenseurs en Physique Quantique](../Chapitre_06_Physique_Quantique/06_introduction.md)*

