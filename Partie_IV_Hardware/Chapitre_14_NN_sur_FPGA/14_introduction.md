# Chapitre 14 : DÃ©ploiement de RÃ©seaux de Neurones sur FPGA

---

## Introduction

Le dÃ©ploiement de rÃ©seaux de neurones sur FPGA prÃ©sente des dÃ©fis uniques liÃ©s aux contraintes mÃ©moire, de latence et d'Ã©nergie. Ce chapitre couvre les stratÃ©gies et techniques pour optimiser ce dÃ©ploiement.

---

## Plan du Chapitre

1. [DÃ©fis SpÃ©cifiques aux FPGA](./14_01_Defis.md)
2. [Architectures de Dataflow](./14_02_Dataflow.md)
3. [ParallÃ©lisme Spatial vs Temporel](./14_03_Parallelisme.md)
4. [Optimisation des AccÃ¨s MÃ©moire](./14_04_Memoire.md)
5. [Frameworks de DÃ©ploiement](./14_05_Frameworks.md)

---

## DÃ©fis Principaux

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DÃ©fis du DÃ©ploiement ML sur FPGA                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Contraintes MÃ©moire                                        â”‚
â”‚     â€¢ BRAM limitÃ© (quelques MB)                                â”‚
â”‚     â€¢ NÃ©cessite compression/quantification                     â”‚
â”‚                                                                 â”‚
â”‚  2. Latence et Throughput                                      â”‚
â”‚     â€¢ Pipeline nÃ©cessaire pour haute frÃ©quence                 â”‚
â”‚     â€¢ Initiation Interval = 1 pour throughput max              â”‚
â”‚                                                                 â”‚
â”‚  3. Consommation Ã‰nergÃ©tique                                   â”‚
â”‚     â€¢ DensitÃ© de calcul vs puissance                           â”‚
â”‚     â€¢ Optimisation des chemins critiques                       â”‚
â”‚                                                                 â”‚
â”‚  4. Ressources LimitÃ©es                                        â”‚
â”‚     â€¢ LUT, DSP, BRAM doivent Ãªtre utilisÃ©s efficacement        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## StratÃ©gies d'Optimisation

### ParallÃ©lisation

```python
class FPGAOptimization:
    """
    Techniques d'optimisation pour FPGA
    """
    
    @staticmethod
    def compute_resource_usage(model, input_shape, reuse_factor=1):
        """
        Estime l'utilisation des ressources FPGA
        """
        total_mults = 0
        total_adds = 0
        
        for layer in model.modules():
            if isinstance(layer, nn.Linear):
                # Multiplications: in_features Ã— out_features
                mults = layer.in_features * layer.out_features
                adds = layer.out_features  # Additions pour biais
                total_mults += mults
                total_adds += adds
            
            elif isinstance(layer, nn.Conv2d):
                # Plus complexe: dÃ©pend de la taille de l'image
                mults = (layer.out_channels * layer.in_channels * 
                        layer.kernel_size[0] * layer.kernel_size[1])
                total_mults += mults
        
        # Ressources nÃ©cessaires (avec reuse)
        dsp_needed = (total_mults + total_adds) // reuse_factor
        
        # Estimation BRAM pour les poids
        weight_bits = sum(p.numel() for p in model.parameters()) * 8  # int8
        bram_18k_needed = weight_bits / (18 * 1024)  # 18k bits par BRAM
        
        return {
            'dsp_estimate': dsp_needed,
            'bram_18k_estimate': bram_18k_needed,
            'total_multiplications': total_mults
        }

# Exemple
model = nn.Sequential(
    nn.Linear(256, 128),
    nn.ReLU(),
    nn.Linear(128, 10)
)

resources = FPGAOptimization.compute_resource_usage(model, (1, 256))

print("Estimation des ressources FPGA:")
print(f"  DSP slices: {resources['dsp_estimate']:.0f}")
print(f"  BRAM 18K: {resources['bram_18k_estimate']:.1f}")
```

---

## Points ClÃ©s Ã  Retenir

> ğŸ“Œ **Le pipelining est essentiel pour atteindre un throughput Ã©levÃ©**

> ğŸ“Œ **Le reuse factor contrÃ´le le compromis ressources/latence**

> ğŸ“Œ **Les accÃ¨s mÃ©moire doivent Ãªtre optimisÃ©s (streaming, burst)**

> ğŸ“Œ **La quantification est souvent nÃ©cessaire pour tenir dans les ressources**

---

*Section suivante : [14.1 DÃ©fis SpÃ©cifiques aux FPGA](./14_01_Defis.md)*

