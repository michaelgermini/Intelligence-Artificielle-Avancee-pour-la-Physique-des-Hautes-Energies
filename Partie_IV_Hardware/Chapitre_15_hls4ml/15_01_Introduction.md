# 15.1 Introduction Ã  hls4ml

---

## Introduction

**hls4ml** (High-Level Synthesis for Machine Learning) est une bibliothÃ¨que open-source qui traduit des modÃ¨les de machine learning entraÃ®nÃ©s dans des frameworks comme Keras, TensorFlow, PyTorch (via ONNX) en code C++ optimisÃ© pour High-Level Synthesis (HLS), permettant ainsi leur dÃ©ploiement sur FPGA.

---

## Historique et Contexte

### Origines

```python
class HLS4MLHistory:
    """
    Historique et contexte de dÃ©veloppement de hls4ml
    """
    
    def __init__(self):
        self.timeline = {
            '2018': {
                'event': 'Publication initiale',
                'context': 'DÃ©veloppÃ© au CERN et Fermilab',
                'motivation': 'Besoin de ML dans les triggers LHC',
                'paper': 'Duarte et al., JINST 13 (2018)'
            },
            '2019': {
                'event': 'Support CNN amÃ©liorÃ©',
                'context': 'Extension pour convolutions 2D',
                'adoption': 'Adoption croissante dans la communautÃ© HEP'
            },
            '2020-2021': {
                'event': 'Support PyTorch, ONNX',
                'context': 'InteropÃ©rabilitÃ© accrue',
                'features': 'Quantization-aware training, pruning'
            },
            '2022+': {
                'event': 'Production deployment',
                'context': 'DÃ©ploiement dans CMS, ATLAS',
                'future': 'Support GPU, optimizations avancÃ©es'
            }
        }
    
    def display_history(self):
        """Affiche l'historique"""
        print("\n" + "="*60)
        print("hls4ml History and Context")
        print("="*60)
        
        for year, info in self.timeline.items():
            print(f"\n{year}:")
            print(f"  Event: {info['event']}")
            print(f"  Context: {info['context']}")
            if 'motivation' in info:
                print(f"  Motivation: {info['motivation']}")
            if 'paper' in info:
                print(f"  Paper: {info['paper']}")

history = HLS4MLHistory()
history.display_history()
```

---

## Pourquoi hls4ml ?

### ProblÃ©matique Initiale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ProblÃ©matique: ML dans les Triggers                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Contraintes LHC:                                               â”‚
â”‚  â€¢ Latence < 4 Î¼s (Level-1 Trigger)                            â”‚
â”‚  â€¢ Throughput: 40 MHz (1 Ã©vÃ©nement / 25 ns)                     â”‚
â”‚  â€¢ Ressources limitÃ©es                                          â”‚
â”‚  â€¢ Consommation Ã©nergÃ©tique contrÃ´lÃ©e                           â”‚
â”‚                                                                 â”‚
â”‚  Solutions existantes insuffisantes:                            â”‚
â”‚  âœ— CPU: Trop lent                                               â”‚
â”‚  âœ— GPU: Latence trop Ã©levÃ©e                                     â”‚
â”‚  âœ— ASIC: Pas flexible, coÃ»teux                                  â”‚
â”‚                                                                 â”‚
â”‚  âœ“ FPGA: Compromis idÃ©al                                        â”‚
â”‚    - Latence dÃ©terministe et faible                             â”‚
â”‚    - Reprogrammable                                             â”‚
â”‚    - ParallÃ©lisme massif                                        â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Avantages de hls4ml

```python
class HLS4MLAdvantages:
    """
    Avantages de hls4ml pour le dÃ©ploiement ML sur FPGA
    """
    
    advantages = {
        'automatic_translation': {
            'description': 'Conversion automatique Keras/TF â†’ HLS C++',
            'benefit': 'Pas besoin d\'Ã©crire du HDL manuellement',
            'impact': 'RÃ©duit temps de dÃ©veloppement de 10Ã—'
        },
        'framework_agnostic': {
            'description': 'Support multiple frameworks',
            'frameworks': ['Keras', 'TensorFlow', 'PyTorch (via ONNX)', 'ONNX'],
            'benefit': 'FlexibilitÃ© dans le choix du framework d\'entraÃ®nement'
        },
        'optimization_aware': {
            'description': 'IntÃ©gration avec compression/quantization',
            'features': ['Quantization', 'Pruning', 'Knowledge distillation'],
            'benefit': 'ModÃ¨les optimisÃ©s avant dÃ©ploiement'
        },
        'configurable': {
            'description': 'ContrÃ´le fin sur ressources/latence',
            'parameters': ['ReuseFactor', 'Precision', 'Strategy'],
            'benefit': 'Trade-offs adaptÃ©s aux contraintes'
        },
        'validated': {
            'description': 'ValidÃ© dans expÃ©riences HEP',
            'applications': ['CMS trigger', 'ATLAS trigger', 'Production use'],
            'benefit': 'Outils Ã©prouvÃ©s en conditions rÃ©elles'
        }
    }
    
    @staticmethod
    def display_advantages():
        """Affiche les avantages"""
        print("\n" + "="*60)
        print("hls4ml Advantages")
        print("="*60)
        
        for adv, info in HLS4MLAdvantages.advantages.items():
            print(f"\n{adv.replace('_', ' ').title()}:")
            print(f"  Description: {info['description']}")
            if isinstance(info.get('frameworks'), list):
                print(f"  Frameworks: {', '.join(info['frameworks'])}")
            if isinstance(info.get('features'), list):
                print(f"  Features: {', '.join(info['features'])}")
            if isinstance(info.get('parameters'), list):
                print(f"  Parameters: {', '.join(info['parameters'])}")
            if isinstance(info.get('applications'), list):
                print(f"  Applications: {', '.join(info['applications'])}")
            print(f"  Benefit: {info['benefit']}")

HLS4MLAdvantages.display_advantages()
```

---

## Architecture de hls4ml

### Pipeline Complet

```python
class HLS4MLPipeline:
    """
    Pipeline complet de hls4ml
    """
    
    def visualize_pipeline(self):
        """Visualise le pipeline"""
        diagram = """
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    hls4ml Pipeline                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Model Input                                                 â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Keras/TF/   â”‚                                            â”‚
â”‚     â”‚  PyTorch/    â”‚                                            â”‚
â”‚     â”‚  ONNX Model  â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  2. Model Parsing                                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Parse Graph â”‚                                            â”‚
â”‚     â”‚  Extract     â”‚                                            â”‚
â”‚     â”‚  Weights     â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  3. Configuration                                               â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Precision   â”‚                                            â”‚
â”‚     â”‚  ReuseFactor â”‚                                            â”‚
â”‚     â”‚  Strategy    â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  4. HLS Code Generation                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Generate    â”‚                                            â”‚
â”‚     â”‚  C++ Code    â”‚                                            â”‚
â”‚     â”‚  (HLS)       â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  5. C Simulation                                                â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Validate    â”‚                                            â”‚
â”‚     â”‚  Algorithm   â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  6. HLS Synthesis (Vivado HLS)                                  â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Generate    â”‚                                            â”‚
â”‚     â”‚  RTL         â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  7. C/RTL Co-simulation                                         â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Verify RTL  â”‚                                            â”‚
â”‚     â”‚  Correctness â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  8. Vivado Implementation                                       â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  Place &     â”‚                                            â”‚
â”‚     â”‚  Route       â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚            â”‚                                                    â”‚
â”‚            â–¼                                                    â”‚
â”‚  9. Bitstream                                                   â”‚
â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                            â”‚
â”‚     â”‚  FPGA        â”‚                                            â”‚
â”‚     â”‚  Bitstream   â”‚                                            â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                            â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""
        return diagram
    
    def explain_stages(self):
        """Explique les Ã©tapes"""
        stages = {
            '1': {
                'name': 'Model Input',
                'description': 'ModÃ¨le entraÃ®nÃ© depuis framework ML',
                'formats': 'HDF5 (Keras), SavedModel (TF), ONNX'
            },
            '2': {
                'name': 'Model Parsing',
                'description': 'Extraction de la structure et des poids',
                'output': 'Graph representation, weights arrays'
            },
            '3': {
                'name': 'Configuration',
                'description': 'ParamÃ¨tres de dÃ©ploiement FPGA',
                'parameters': 'Precision, ReuseFactor, Strategy, etc.'
            },
            '4': {
                'name': 'HLS Code Generation',
                'description': 'GÃ©nÃ©ration code C++ pour HLS',
                'output': 'Project files, C++ headers, implementation'
            },
            '5': {
                'name': 'C Simulation',
                'description': 'Validation algorithmique',
                'purpose': 'VÃ©rifier que le code C++ est correct'
            },
            '6': {
                'name': 'HLS Synthesis',
                'description': 'Conversion C++ â†’ RTL via Vivado HLS',
                'output': 'Verilog/VHDL RTL'
            },
            '7': {
                'name': 'C/RTL Co-simulation',
                'description': 'Validation RTL vs C',
                'purpose': 'S\'assurer que RTL correspond au C++'
            },
            '8': {
                'name': 'Vivado Implementation',
                'description': 'Place & Route sur FPGA',
                'output': 'Placed and routed design'
            },
            '9': {
                'name': 'Bitstream',
                'description': 'GÃ©nÃ©ration fichier de configuration',
                'output': '.bit file pour programmer FPGA'
            }
        }
        
        print("\n" + "="*60)
        print("Pipeline Stages Explanation")
        print("="*60)
        
        for stage, info in stages.items():
            print(f"\nStage {stage}: {info['name']}")
            print(f"  Description: {info['description']}")
            if 'formats' in info:
                print(f"  Formats: {info['formats']}")
            if 'output' in info:
                print(f"  Output: {info['output']}")
            if 'parameters' in info:
                print(f"  Parameters: {info['parameters']}")
            if 'purpose' in info:
                print(f"  Purpose: {info['purpose']}")

pipeline = HLS4MLPipeline()
print(pipeline.visualize_pipeline())
pipeline.explain_stages()
```

---

## Installation et Premiers Pas

### Installation

```python
# Installation de hls4ml
"""
# Via pip
pip install hls4ml

# Ou depuis source
git clone https://github.com/fastmachinelearning/hls4ml.git
cd hls4ml
pip install -e .

# DÃ©pendances
# - TensorFlow ou PyTorch (pour modÃ¨les)
# - Vivado HLS (pour synthÃ¨se, optionnel pour C sim)
# - NumPy, h5py, pyyaml
"""

import hls4ml
import numpy as np
from tensorflow import keras

# VÃ©rification de l'installation
print(f"hls4ml version: {hls4ml.__version__}")

# Exemple minimal
def minimal_example():
    """Exemple minimal d'utilisation"""
    
    # 1. CrÃ©er un modÃ¨le simple
    model = keras.Sequential([
        keras.layers.Dense(10, activation='relu', input_shape=(8,)),
        keras.layers.Dense(5, activation='softmax')
    ])
    
    model.compile(optimizer='adam', loss='categorical_crossentropy')
    
    # 2. Configuration de base
    config = hls4ml.utils.config_from_keras_model(model, granularity='name')
    
    # 3. Conversion
    hls_model = hls4ml.converters.convert_from_keras_model(
        model,
        hls_config=config,
        output_dir='my_hls_project',
        part='xc7z020clg400-1'  # Zynq-7000
    )
    
    # 4. Compilation (gÃ©nÃ¨re code C++)
    hls_model.compile()
    
    return hls_model

# hls_model = minimal_example()
```

---

## Concepts ClÃ©s

### PrÃ©cision (Precision)

```python
class PrecisionConcepts:
    """
    Concepts de prÃ©cision dans hls4ml
    """
    
    def __init__(self):
        self.precision_types = {
            'ap_fixed<W,I>': {
                'description': 'Fixed-point signed',
                'W': 'Total width in bits',
                'I': 'Integer bits',
                'F': 'Fractional bits = W - I',
                'range': '[-2^(I-1), 2^(I-1) - 2^-F]',
                'example': 'ap_fixed<16,6> = 16 bits total, 6 integer, 10 fractional'
            },
            'ap_ufixed<W,I>': {
                'description': 'Fixed-point unsigned',
                'range': '[0, 2^I - 2^-F]',
                'example': 'ap_ufixed<8,4> = 8 bits, unsigned, 4 integer'
            },
            'ap_int<W>': {
                'description': 'Integer signed',
                'range': '[-2^(W-1), 2^(W-1)-1]',
                'example': 'ap_int<8> = 8-bit signed integer'
            },
            'ap_uint<W>': {
                'description': 'Integer unsigned',
                'range': '[0, 2^W-1]',
                'example': 'ap_uint<8> = 8-bit unsigned integer'
            }
        }
    
    def display_precisions(self):
        """Affiche les types de prÃ©cision"""
        print("\n" + "="*60)
        print("Precision Types in hls4ml")
        print("="*60)
        
        for ptype, info in self.precision_types.items():
            print(f"\n{ptype}:")
            for key, value in info.items():
                print(f"  {key}: {value}")
    
    def calculate_precision_requirements(self, data_range, error_tolerance):
        """
        Calcule la prÃ©cision nÃ©cessaire
        
        Args:
            data_range: (min, max)
            error_tolerance: Maximum acceptable error
        """
        min_val, max_val = data_range
        range_val = max_val - min_val
        
        # Bits entiers nÃ©cessaires
        integer_bits = int(np.ceil(np.log2(max(abs(min_val), abs(max_val)) + 1))) + 1
        
        # Bits fractionnaires pour l'erreur
        fractional_bits = int(np.ceil(-np.log2(error_tolerance)))
        
        total_bits = integer_bits + fractional_bits
        
        return {
            'integer_bits': integer_bits,
            'fractional_bits': fractional_bits,
            'total_bits': total_bits,
            'recommended': f'ap_fixed<{total_bits},{integer_bits}>'
        }

precision = PrecisionConcepts()
precision.display_precisions()

# Exemple de calcul
prec_req = precision.calculate_precision_requirements(
    data_range=(-10.0, 10.0),
    error_tolerance=0.01
)
print("\n" + "="*60)
print("Precision Requirements Example")
print("="*60)
print(f"  Data range: [-10, 10]")
print(f"  Error tolerance: 0.01")
print(f"  Recommended: {prec_req['recommended']}")
print(f"  Integer bits: {prec_req['integer_bits']}")
print(f"  Fractional bits: {prec_req['fractional_bits']}")
```

---

## Exercices

### Exercice 15.1.1
Installez hls4ml et convertissez un modÃ¨le Keras simple de 2 couches dense avec diffÃ©rentes prÃ©cisions.

### Exercice 15.1.2
Calculez la prÃ©cision optimale pour des donnÃ©es dans la plage [-5, 5] avec une tolÃ©rance d'erreur de 0.001.

---

## Points ClÃ©s Ã  Retenir

> ğŸ“Œ **hls4ml traduit automatiquement ML â†’ HLS â†’ FPGA**

> ğŸ“Œ **Support multiple frameworks: Keras, TensorFlow, PyTorch, ONNX**

> ğŸ“Œ **Pipeline: Model â†’ Parsing â†’ Config â†’ HLS Code â†’ Synthesis â†’ Bitstream**

> ğŸ“Œ **PrÃ©cision configurable: ap_fixed, ap_int, etc.**

> ğŸ“Œ **ValidÃ© en production dans les expÃ©riences HEP**

---

*Section suivante : [15.2 ModÃ¨les SupportÃ©s et Limitations](./15_02_Modeles.md)*

