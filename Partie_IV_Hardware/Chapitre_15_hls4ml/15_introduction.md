# Chapitre 15 : hls4ml - Machine Learning pour FPGA

---

## Introduction

**hls4ml** est une bibliothÃ¨que open-source qui traduit des modÃ¨les de machine learning en firmware FPGA via High-Level Synthesis (HLS). DÃ©veloppÃ©e au CERN et Fermilab, elle est devenue l'outil de rÃ©fÃ©rence pour le dÃ©ploiement de ML dans les systÃ¨mes de trigger des expÃ©riences de physique des particules.

---

## Plan du Chapitre

1. [Introduction Ã  hls4ml](./15_01_Introduction.md)
2. [ModÃ¨les SupportÃ©s et Limitations](./15_02_Modeles.md)
3. [Configuration et Optimisation](./15_03_Configuration.md)
4. [StratÃ©gies de ParallÃ©lisation](./15_04_Parallelisation.md)
5. [IntÃ©gration avec les Workflows de Physique](./15_05_Integration.md)
6. [Ã‰tudes de Cas au CERN](./15_06_Cas_CERN.md)

---

## Vue d'Ensemble de hls4ml

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Pipeline hls4ml                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   Keras/    â”‚    â”‚   hls4ml    â”‚    â”‚    HLS      â”‚         â”‚
â”‚  â”‚  PyTorch    â”‚â”€â”€â”€â–¶â”‚  Converter  â”‚â”€â”€â”€â–¶â”‚   (Vivado)  â”‚         â”‚
â”‚  â”‚   Model     â”‚    â”‚             â”‚    â”‚             â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                               â”‚                 â”‚
â”‚                                               â–¼                 â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                     â”‚   Bitstream â”‚â—€â”€â”€â”€â”‚  Synthesis  â”‚         â”‚
â”‚                     â”‚    (FPGA)   â”‚    â”‚   & P&R     â”‚         â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Installation et Configuration

```python
# Installation
# pip install hls4ml

import hls4ml
import numpy as np
from tensorflow import keras

# VÃ©rification de l'installation
print(f"hls4ml version: {hls4ml.__version__}")

# Configuration du backend
hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']
hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'
hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'
```

---

## Conversion d'un ModÃ¨le Keras

```python
def create_simple_classifier():
    """CrÃ©e un classificateur simple pour dÃ©monstration"""
    model = keras.Sequential([
        keras.layers.Dense(64, activation='relu', input_shape=(16,)),
        keras.layers.Dense(32, activation='relu'),
        keras.layers.Dense(16, activation='relu'),
        keras.layers.Dense(5, activation='softmax')
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy')
    return model

def convert_to_hls4ml(keras_model, output_dir='my_hls_project'):
    """
    Convertit un modÃ¨le Keras en projet HLS
    """
    # Configuration de base
    config = hls4ml.utils.config_from_keras_model(keras_model, granularity='name')
    
    # Affiche la configuration par dÃ©faut
    print("Configuration par dÃ©faut:")
    print(f"  PrÃ©cision: {config['Model']['Precision']}")
    print(f"  ReuseFactor: {config['Model']['ReuseFactor']}")
    
    # Personnalisation de la configuration
    config['Model']['Precision'] = 'ap_fixed<16,6>'
    config['Model']['ReuseFactor'] = 1  # Fully parallel
    
    # Configuration par couche
    for layer in config['LayerName'].keys():
        config['LayerName'][layer]['Precision'] = {
            'weight': 'ap_fixed<8,2>',
            'bias': 'ap_fixed<8,2>',
            'result': 'ap_fixed<16,6>'
        }
    
    # Conversion
    hls_model = hls4ml.converters.convert_from_keras_model(
        keras_model,
        hls_config=config,
        output_dir=output_dir,
        part='xcu250-figd2104-2L-e'  # FPGA Alveo U250
    )
    
    return hls_model, config

# Exemple
keras_model = create_simple_classifier()
hls_model, config = convert_to_hls4ml(keras_model)

# Compilation (gÃ©nÃ¨re le code HLS)
hls_model.compile()

# SynthÃ¨se (nÃ©cessite Vivado HLS)
# hls_model.build(csim=True, synth=True, cosim=True)
```

---

## Configuration AvancÃ©e

```python
class HLS4MLConfigurator:
    """
    Utilitaire pour configurer hls4ml de maniÃ¨re optimale
    """
    
    @staticmethod
    def create_config(model, 
                     precision='ap_fixed<16,6>',
                     reuse_factor=1,
                     strategy='Latency'):
        """
        CrÃ©e une configuration personnalisÃ©e
        
        Args:
            precision: PrÃ©cision par dÃ©faut
            reuse_factor: 1 = fully parallel, >1 = resource sharing
            strategy: 'Latency' ou 'Resource'
        """
        config = hls4ml.utils.config_from_keras_model(model, granularity='name')
        
        config['Model']['Precision'] = precision
        config['Model']['ReuseFactor'] = reuse_factor
        config['Model']['Strategy'] = strategy
        
        return config
    
    @staticmethod
    def optimize_for_latency(config, target_latency_ns=100):
        """
        Optimise pour minimiser la latence
        """
        # Fully parallel
        config['Model']['ReuseFactor'] = 1
        config['Model']['Strategy'] = 'Latency'
        
        # Pipeline initiation interval = 1
        for layer in config['LayerName'].keys():
            config['LayerName'][layer]['ReuseFactor'] = 1
        
        return config
    
    @staticmethod
    def optimize_for_resources(config, target_utilization=0.8):
        """
        Optimise pour minimiser l'utilisation de ressources
        """
        # Augmente le reuse factor
        config['Model']['Strategy'] = 'Resource'
        
        # Estime le reuse factor nÃ©cessaire
        # (basÃ© sur la taille du modÃ¨le et les ressources cibles)
        
        return config
    
    @staticmethod
    def layer_specific_precision(config, layer_precisions):
        """
        Configure la prÃ©cision par couche
        
        layer_precisions: dict {layer_name: {'weight': ..., 'bias': ..., 'result': ...}}
        """
        for layer_name, precisions in layer_precisions.items():
            if layer_name in config['LayerName']:
                config['LayerName'][layer_name]['Precision'] = precisions
        
        return config

# Exemple d'utilisation
config = HLS4MLConfigurator.create_config(keras_model)
config = HLS4MLConfigurator.optimize_for_latency(config)

# PrÃ©cisions spÃ©cifiques
layer_prec = {
    'dense': {'weight': 'ap_fixed<6,2>', 'bias': 'ap_fixed<6,2>', 'result': 'ap_fixed<12,4>'},
    'dense_1': {'weight': 'ap_fixed<8,2>', 'bias': 'ap_fixed<8,2>', 'result': 'ap_fixed<14,5>'},
}
config = HLS4MLConfigurator.layer_specific_precision(config, layer_prec)
```

---

## StratÃ©gies de ParallÃ©lisation

```python
class ParallelizationStrategies:
    """
    DiffÃ©rentes stratÃ©gies de parallÃ©lisation pour hls4ml
    """
    
    @staticmethod
    def fully_parallel(config):
        """
        ParallÃ©lisation complÃ¨te: latence minimale, ressources maximales
        
        Chaque multiplication est implÃ©mentÃ©e en hardware dÃ©diÃ©
        """
        config['Model']['ReuseFactor'] = 1
        config['Model']['Strategy'] = 'Latency'
        
        for layer in config['LayerName'].keys():
            config['LayerName'][layer]['ReuseFactor'] = 1
        
        return config
    
    @staticmethod
    def resource_sharing(config, reuse_factor):
        """
        Partage de ressources: ressources rÃ©duites, latence augmentÃ©e
        
        Les multiplieurs sont rÃ©utilisÃ©s sur plusieurs cycles
        """
        config['Model']['ReuseFactor'] = reuse_factor
        config['Model']['Strategy'] = 'Resource'
        
        return config
    
    @staticmethod
    def layer_fusion(model):
        """
        Fusion de couches pour rÃ©duire les accÃ¨s mÃ©moire
        
        Ex: Conv + BatchNorm + ReLU â†’ une seule opÃ©ration
        """
        # hls4ml fait automatiquement certaines fusions
        # Batch normalization est fusionnÃ©e avec la couche prÃ©cÃ©dente
        pass
    
    @staticmethod
    def estimate_resources(config, model):
        """
        Estime l'utilisation de ressources
        """
        # Compte les multiplications
        total_mults = 0
        for layer in model.layers:
            if hasattr(layer, 'kernel'):
                weights = layer.get_weights()[0]
                total_mults += weights.size
        
        reuse_factor = config['Model']['ReuseFactor']
        
        # DSP slices nÃ©cessaires (approximation)
        dsp_needed = total_mults // reuse_factor
        
        # Latence estimÃ©e (cycles)
        latency_cycles = total_mults // (total_mults // reuse_factor)
        
        return {
            'total_multiplications': total_mults,
            'dsp_estimate': dsp_needed,
            'latency_cycles': latency_cycles
        }

# Comparaison des stratÃ©gies
print("Comparaison des stratÃ©gies de parallÃ©lisation:")

for rf in [1, 4, 16, 64]:
    config = HLS4MLConfigurator.create_config(keras_model)
    config['Model']['ReuseFactor'] = rf
    
    resources = ParallelizationStrategies.estimate_resources(config, keras_model)
    print(f"\nReuseFactor={rf}:")
    print(f"  DSP estimÃ©s: {resources['dsp_estimate']}")
    print(f"  Latence (cycles): {resources['latency_cycles']}")
```

---

## Validation et Test

```python
class HLS4MLValidator:
    """
    Outils de validation pour les modÃ¨les hls4ml
    """
    
    @staticmethod
    def compare_predictions(keras_model, hls_model, test_data, tolerance=1e-3):
        """
        Compare les prÃ©dictions Keras vs HLS
        """
        # PrÃ©dictions Keras
        keras_pred = keras_model.predict(test_data)
        
        # PrÃ©dictions HLS (simulation C)
        hls_pred = hls_model.predict(test_data)
        
        # Comparaison
        max_diff = np.abs(keras_pred - hls_pred).max()
        mean_diff = np.abs(keras_pred - hls_pred).mean()
        
        # VÃ©rification de la classification
        keras_class = np.argmax(keras_pred, axis=1)
        hls_class = np.argmax(hls_pred, axis=1)
        accuracy_match = (keras_class == hls_class).mean()
        
        return {
            'max_difference': max_diff,
            'mean_difference': mean_diff,
            'classification_match': accuracy_match,
            'within_tolerance': max_diff < tolerance
        }
    
    @staticmethod
    def profile_latency(hls_model, n_samples=1000):
        """
        Profile la latence d'infÃ©rence
        """
        import time
        
        test_input = np.random.randn(1, hls_model.config.get_input_shape()[0])
        
        # Warmup
        for _ in range(10):
            _ = hls_model.predict(test_input)
        
        # Mesure
        start = time.time()
        for _ in range(n_samples):
            _ = hls_model.predict(test_input)
        elapsed = time.time() - start
        
        return {
            'total_time_ms': elapsed * 1000,
            'avg_latency_us': (elapsed / n_samples) * 1e6,
            'throughput_khz': n_samples / elapsed / 1000
        }
    
    @staticmethod
    def analyze_synthesis_report(report_path):
        """
        Parse le rapport de synthÃ¨se Vivado
        """
        # Le rapport contient:
        # - Utilisation des ressources (LUT, FF, BRAM, DSP)
        # - Timing (frÃ©quence max, latence)
        # - Warnings et erreurs
        
        # Parsing simplifiÃ©
        resources = {
            'LUT': 0,
            'FF': 0,
            'BRAM': 0,
            'DSP': 0
        }
        
        timing = {
            'clock_period_ns': 0,
            'latency_cycles': 0,
            'initiation_interval': 0
        }
        
        return {'resources': resources, 'timing': timing}

# Validation
"""
test_data = np.random.randn(100, 16).astype(np.float32)
validation = HLS4MLValidator.compare_predictions(keras_model, hls_model, test_data)
print(f"Validation: {validation}")
"""
```

---

## Applications au CERN

```python
class CERNTriggerModel:
    """
    Exemple de modÃ¨le pour le trigger L1 du CMS
    """
    
    @staticmethod
    def create_jet_tagger(n_features=16, n_classes=5):
        """
        CrÃ©e un tagger de jets pour le trigger
        
        Contraintes:
        - Latence < 100 ns
        - Ressources limitÃ©es
        """
        model = keras.Sequential([
            keras.layers.Dense(32, activation='relu', 
                             input_shape=(n_features,),
                             kernel_initializer='glorot_uniform'),
            keras.layers.Dense(16, activation='relu'),
            keras.layers.Dense(n_classes, activation='softmax')
        ])
        
        return model
    
    @staticmethod
    def get_trigger_config():
        """
        Configuration optimisÃ©e pour le trigger
        """
        config = {
            'Model': {
                'Precision': 'ap_fixed<10,4>',
                'ReuseFactor': 1,
                'Strategy': 'Latency'
            },
            'LayerName': {
                'dense': {
                    'Precision': {
                        'weight': 'ap_fixed<6,1>',
                        'bias': 'ap_fixed<6,1>',
                        'result': 'ap_fixed<10,4>'
                    },
                    'ReuseFactor': 1
                },
                'dense_1': {
                    'Precision': {
                        'weight': 'ap_fixed<6,1>',
                        'bias': 'ap_fixed<6,1>',
                        'result': 'ap_fixed<10,4>'
                    },
                    'ReuseFactor': 1
                },
                'dense_2': {
                    'Precision': {
                        'weight': 'ap_fixed<8,2>',
                        'bias': 'ap_fixed<8,2>',
                        'result': 'ap_fixed<12,6>'
                    },
                    'ReuseFactor': 1
                }
            }
        }
        return config
    
    @staticmethod
    def validate_for_trigger(hls_model, target_latency_ns=100, clock_freq_mhz=200):
        """
        Valide que le modÃ¨le respecte les contraintes du trigger
        """
        # Latence en cycles
        target_cycles = target_latency_ns * clock_freq_mhz / 1000
        
        # Parse le rapport de synthÃ¨se
        # actual_latency = ...
        
        # VÃ©rifie les ressources disponibles
        # ...
        
        return {
            'target_cycles': target_cycles,
            'meets_latency': True,  # Ã€ vÃ©rifier
            'meets_resources': True  # Ã€ vÃ©rifier
        }

# CrÃ©ation et conversion
jet_model = CERNTriggerModel.create_jet_tagger()
trigger_config = CERNTriggerModel.get_trigger_config()

print("ModÃ¨le de jet tagger pour trigger:")
jet_model.summary()
```

---

## Exercices

### Exercice 15.1
Convertissez un CNN simple en hls4ml et mesurez l'impact de diffÃ©rentes prÃ©cisions sur la prÃ©cision de classification.

### Exercice 15.2
Optimisez un modÃ¨le pour atteindre une latence de 50 ns sur un FPGA Xilinx.

### Exercice 15.3
Comparez les ressources utilisÃ©es pour diffÃ©rentes stratÃ©gies de reuse factor.

---

## Points ClÃ©s Ã  Retenir

> ğŸ“Œ **hls4ml traduit automatiquement les modÃ¨les ML en firmware FPGA**

> ğŸ“Œ **Le compromis latence/ressources est contrÃ´lÃ© par le ReuseFactor**

> ğŸ“Œ **La quantification est essentielle pour tenir dans les ressources FPGA**

> ğŸ“Œ **La validation C-simulation vs RTL est cruciale avant dÃ©ploiement**

---

## RÃ©fÃ©rences

1. Duarte, J. et al. "Fast inference of deep neural networks in FPGAs for particle physics." JINST 13 (2018)
2. hls4ml Documentation: https://fastmachinelearning.org/hls4ml/
3. Summers, S. et al. "Fast inference of Boosted Decision Trees in FPGAs for particle physics." JINST 15 (2020)

---

*Chapitre suivant : [Chapitre 16 - Hardware-Aware Neural Architecture Search](../Chapitre_16_Hardware_NAS/16_introduction.md)*

