# 16.1 Principes du Neural Architecture Search

---

## Introduction

Le **Neural Architecture Search (NAS)** automatise la recherche des meilleures architectures de rÃ©seaux de neurones. Cette section prÃ©sente les principes fondamentaux du NAS et leur extension au **Hardware-Aware NAS**.

---

## ProblÃ¨me du NAS

### DÃ©finition

```python
class NASProblem:
    """
    Formulation du problÃ¨me NAS
    """
    
    def __init__(self):
        self.problem_formulation = """
        Trouver l'architecture optimale A* qui maximise la performance
        sur une tÃ¢che donnÃ©e, dans un espace de recherche dÃ©fini.
        
        A* = argmax_{A in SearchSpace} Performance(A, D)
        
        oÃ¹:
        - A: Architecture
        - SearchSpace: Espace de recherche d'architectures
        - D: Dataset
        - Performance: MÃ©trique (accuracy, F1-score, etc.)
        """
    
    def display_problem(self):
        """Affiche la formulation du problÃ¨me"""
        print("\n" + "="*60)
        print("NAS Problem Formulation")
        print("="*60)
        print(self.problem_formulation)

nas_problem = NASProblem()
nas_problem.display_problem()
```

---

## Composants du NAS

### Structure GÃ©nÃ©rale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Composants du NAS                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  1. Search Space                                                â”‚
â”‚     â””â”€ DÃ©finit les architectures possibles                     â”‚
â”‚                                                                 â”‚
â”‚  2. Search Strategy                                             â”‚
â”‚     â””â”€ Algorithme de recherche (random, evolutionary, etc.)    â”‚
â”‚                                                                 â”‚
â”‚  3. Performance Estimator                                       â”‚
â”‚     â””â”€ Estime la performance d'une architecture                â”‚
â”‚                                                                 â”‚
â”‚  4. Evaluation Function                                         â”‚
â”‚     â””â”€ Ã‰value rÃ©ellement une architecture (entraÃ®nement)       â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Search Space

### Types d'Espaces de Recherche

```python
class SearchSpace:
    """
    Espaces de recherche d'architectures
    """
    
    def __init__(self):
        self.space_types = {
            'micro_architecture': {
                'description': 'Recherche dans les cellules/blocs',
                'example': 'Cellules pour CNN (conv blocks)',
                'size': 'Relativement petit',
                'use_case': 'Recherche efficace de cellules rÃ©utilisables'
            },
            'macro_architecture': {
                'description': 'Recherche dans la structure globale',
                'example': "Nombre de couches, largeur de l'architecture",
                'size': 'Plus grand',
                'use_case': 'Recherche complÃ¨te de l\'architecture'
            },
            'hierarchical': {
                'description': 'Recherche Ã  plusieurs niveaux',
                'example': 'Cellules + composition de cellules',
                'size': 'TrÃ¨s grand mais structurÃ©',
                'use_case': 'Meilleur compromis expressivitÃ©/efficacitÃ©'
            }
        }
    
    def create_micro_space(self):
        """
        CrÃ©e un espace de recherche micro-architecture
        
        Exemple: Recherche de cellules CNN
        """
        space = {
            'operations': [
                'conv_3x3',
                'conv_5x5',
                'depthwise_conv',
                'max_pool',
                'avg_pool',
                'identity',
                'skip_connection'
            ],
            'number_of_ops_per_cell': [2, 3, 4],
            'normalization': ['batch_norm', 'layer_norm', 'none'],
            'activation': ['relu', 'swish', 'gelu']
        }
        return space
    
    def create_macro_space(self):
        """
        CrÃ©e un espace de recherche macro-architecture
        
        Exemple: Architecture complÃ¨te
        """
        space = {
            'num_layers': [3, 4, 5, 6, 7, 8],
            'layer_width': [64, 128, 256, 512],
            'layer_types': ['dense', 'conv2d'],
            'activation': ['relu', 'gelu', 'swish'],
            'use_dropout': [True, False],
            'dropout_rate': [0.1, 0.2, 0.3, 0.5]
        }
        return space
    
    def display_space_types(self):
        """Affiche les types d'espaces"""
        print("\n" + "="*60)
        print("Search Space Types")
        print("="*60)
        
        for space_type, info in self.space_types.items():
            print(f"\n{space_type.replace('_', ' ').title()}:")
            for key, value in info.items():
                print(f"  {key}: {value}")

search_space = SearchSpace()
search_space.display_space_types()

# Exemples
micro = search_space.create_micro_space()
macro = search_space.create_macro_space()

print("\n" + "="*60)
print("Example Search Spaces")
print("="*60)
print("\nMicro-architecture space:")
for key, value in micro.items():
    print(f"  {key}: {value}")

print("\nMacro-architecture space:")
for key, value in macro.items():
    print(f"  {key}: {value}")
```

---

## Search Strategy

### Algorithmes de Recherche

```python
class SearchStrategy:
    """
    StratÃ©gies de recherche NAS
    """
    
    def __init__(self):
        self.strategies = {
            'random_search': {
                'description': 'Recherche alÃ©atoire dans l\'espace',
                'pros': ['Simple', 'Pas de biais', 'Facile Ã  parallÃ©liser'],
                'cons': ['Peu efficace', 'Pas de guidance'],
                'complexity': 'O(n) pour n architectures'
            },
            'grid_search': {
                'description': 'Recherche exhaustive sur grille discrÃ¨te',
                'pros': ['Complet sur la grille', 'DÃ©terministe'],
                'cons': ['Combinatorial explosion', 'Impossible pour grands espaces'],
                'complexity': 'O(âˆ|dimensions|)'
            },
            'evolutionary': {
                'description': 'Algorithmes Ã©volutionnaires (genetic algorithms)',
                'pros': ['Efficace', 'Peut explorer large espace'],
                'cons': ['Beaucoup d\'Ã©valuations nÃ©cessaires'],
                'complexity': 'O(generations Ã— population_size Ã— eval_time)'
            },
            'reinforcement_learning': {
                'description': 'RL pour guider la recherche',
                'pros': ['Apprentissage de bonnes stratÃ©gies', 'Efficace Ã  long terme'],
                'cons': ['Complexe', 'Besoin de beaucoup d\'Ã©valuations'],
                'complexity': 'O(episodes Ã— eval_time)'
            },
            'differentiable': {
                'description': 'NAS diffÃ©rentiable (DARTS, etc.)',
                'pros': ['Rapide (gradient-based)', 'Efficace'],
                'cons': ['LimitÃ© Ã  certains espaces', 'Approximation continue'],
                'complexity': 'O(training_epochs Ã— forward_pass)'
            },
            'bayesian_optimization': {
                'description': 'Optimisation bayÃ©sienne',
                'pros': ['Efficace pour espaces continus', 'Peu d\'Ã©valuations'],
                'cons': ['Complexe', 'NÃ©cessite modÃ¨le probabiliste'],
                'complexity': 'O(nÂ²) pour n Ã©valuations'
            }
        }
    
    def display_strategies(self):
        """Affiche les stratÃ©gies"""
        print("\n" + "="*60)
        print("Search Strategies")
        print("="*60)
        
        for strategy, info in self.strategies.items():
            print(f"\n{strategy.replace('_', ' ').title()}:")
            print(f"  Description: {info['description']}")
            print(f"  Pros:")
            for pro in info['pros']:
                print(f"    + {pro}")
            print(f"  Cons:")
            for con in info['cons']:
                print(f"    - {con}")
            print(f"  Complexity: {info['complexity']}")

strategy = SearchStrategy()
strategy.display_strategies()
```

---

## Performance Estimation

### MÃ©thodes d'Estimation

```python
class PerformanceEstimation:
    """
    Estimation de la performance d'une architecture
    """
    
    def __init__(self):
        self.estimation_methods = {
            'full_training': {
                'description': 'EntraÃ®nement complet du modÃ¨le',
                'accuracy': 'TrÃ¨s prÃ©cise',
                'cost': 'TrÃ¨s Ã©levÃ© (heures/jours)',
                'use_case': 'Ã‰valuation finale, petites recherches'
            },
            'partial_training': {
                'description': 'EntraÃ®nement partiel (quelques epochs)',
                'accuracy': 'Assez prÃ©cise',
                'cost': 'ModÃ©rÃ©',
                'use_case': 'Recherche NAS standard'
            },
            'weight_sharing': {
                'description': 'Partage des poids entre architectures',
                'accuracy': 'ModÃ©rÃ©e',
                'cost': 'Faible',
                'use_case': 'ENAS, One-shot NAS'
            },
            'performance_predictor': {
                'description': 'ModÃ¨le ML qui prÃ©dit la performance',
                'accuracy': 'Variable (dÃ©pend du predictor)',
                'cost': 'TrÃ¨s faible',
                'use_case': 'Recherche rapide, prÃ©-filtrage'
            },
            'gradient_based_proxy': {
                'description': 'MÃ©triques basÃ©es sur gradients',
                'accuracy': 'Faible-modÃ©rÃ©e',
                'cost': 'TrÃ¨s faible',
                'use_case': 'Proxies rapides, premiÃ¨res Ã©tapes'
            }
        }
    
    def train_partial(self, model, train_loader, epochs=5):
        """
        EntraÃ®nement partiel pour estimation rapide
        
        Args:
            model: ModÃ¨le Ã  entraÃ®ner
            train_loader: DataLoader
            epochs: Nombre d'epochs (rÃ©duit)
        
        Returns:
            Accuracy estimÃ©e
        """
        import torch.nn as nn
        import torch.optim as optim
        
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(model.parameters(), lr=0.001)
        
        model.train()
        for epoch in range(epochs):
            for data, target in train_loader:
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
        
        # Ã‰valuation rapide
        model.eval()
        correct = 0
        total = 0
        with torch.no_grad():
            for data, target in train_loader:
                output = model(data)
                pred = output.argmax(dim=1)
                correct += (pred == target).sum().item()
                total += target.size(0)
        
        return correct / total
    
    def performance_predictor(self, arch_features):
        """
        PrÃ©dicteur ML de performance
        
        Args:
            arch_features: CaractÃ©ristiques de l'architecture
                (nombre paramÃ¨tres, profondeur, largeur, etc.)
        
        Returns:
            Performance prÃ©dite
        """
        # Exemple simplifiÃ©: corrÃ©lation avec nombre de paramÃ¨tres
        # En pratique, utiliser un modÃ¨le ML entraÃ®nÃ©
        n_params = arch_features.get('num_params', 0)
        depth = arch_features.get('depth', 0)
        
        # Approximation simplifiÃ©e
        predicted_perf = min(0.5 + (n_params / 1e6) * 0.3 + depth * 0.01, 0.95)
        return predicted_perf
    
    def display_methods(self):
        """Affiche les mÃ©thodes"""
        print("\n" + "="*60)
        print("Performance Estimation Methods")
        print("="*60)
        
        for method, info in self.estimation_methods.items():
            print(f"\n{method.replace('_', ' ').title()}:")
            print(f"  Description: {info['description']}")
            print(f"  Accuracy: {info['accuracy']}")
            print(f"  Cost: {info['cost']}")
            print(f"  Use case: {info['use_case']}")

estimation = PerformanceEstimation()
estimation.display_methods()
```

---

## Hardware-Aware NAS

### Extension du NAS Standard

```python
class HardwareAwareNAS:
    """
    Extension du NAS pour prendre en compte le hardware
    """
    
    def __init__(self):
        self.extension = """
        Hardware-Aware NAS Ã©tend le problÃ¨me NAS standard:
        
        NAS Standard:
        A* = argmax_{A} Accuracy(A, D)
        
        Hardware-Aware NAS:
        A* = argmax_{A} f(Accuracy(A, D), Hardware_Metrics(A, H))
        
        oÃ¹:
        - Hardware_Metrics: Latence, Ã©nergie, surface, etc.
        - H: Configuration hardware cible
        - f: Fonction de compromis multi-objectif
        """
    
    def multi_objective_formulation(self):
        """
        Formulation multi-objectif
        """
        objectives = {
            'primary': 'Accuracy (ou autre mÃ©trique ML)',
            'secondary': [
                'Latency (ns)',
                'Energy (pJ)',
                'Model size (MB)',
                'Resource usage (LUT, DSP, etc.)'
            ]
        }
        
        methods = {
            'weighted_sum': {
                'formulation': 'score = w1*accuracy - w2*latency - w3*energy',
                'pros': ['Simple', 'ContrÃ´le direct des poids'],
                'cons': ['Choix des poids arbitraire', 'Pareto front implicite']
            },
            'pareto_optimization': {
                'formulation': 'Trouve le front de Pareto',
                'pros': ['Pas besoin de poids', 'Toutes les solutions optimales'],
                'cons': ['Plusieurs solutions', 'Choix final nÃ©cessaire']
            },
            'constrained_optimization': {
                'formulation': 'Max accuracy s.t. latency < threshold',
                'pros': ['Contraintes explicites', 'Clair pour applications'],
                'cons': 'Choix du seuil critique'
            }
        }
        
        return objectives, methods
    
    def display_extension(self):
        """Affiche l'extension hardware-aware"""
        print("\n" + "="*60)
        print("Hardware-Aware NAS Extension")
        print("="*60)
        print(self.extension)
        
        objectives, methods = self.multi_objective_formulation()
        
        print("\nObjectives:")
        print(f"  Primary: {objectives['primary']}")
        print("  Secondary:")
        for obj in objectives['secondary']:
            print(f"    â€¢ {obj}")
        
        print("\nMulti-objective Methods:")
        for method, info in methods.items():
            print(f"\n  {method.replace('_', ' ').title()}:")
            print(f"    Formulation: {info['formulation']}")
            print(f"    Pros:")
            for pro in info['pros']:
                print(f"      + {pro}")
            if 'cons' in info:
                if isinstance(info['cons'], list):
                    for con in info['cons']:
                        print(f"      - {con}")
                else:
                    print(f"    Cons: {info['cons']}")

hardware_nas = HardwareAwareNAS()
hardware_nas.display_extension()
```

---

## Workflow Typique du Hardware-Aware NAS

```python
class NASWorkflow:
    """
    Workflow typique d'un Hardware-Aware NAS
    """
    
    def generate_workflow(self):
        """GÃ©nÃ¨re le workflow"""
        workflow = """
Hardware-Aware NAS Workflow:

1. Problem Definition
   â”œâ”€ DÃ©finir tÃ¢che ML
   â”œâ”€ Identifier contraintes hardware
   â””â”€ DÃ©finir mÃ©triques objectives

2. Search Space Design
   â”œâ”€ DÃ©finir espace d'architectures
   â”œâ”€ Inclure contraintes hardware dans l'espace
   â””â”€ Valider espace de recherche

3. Hardware Model Setup
   â”œâ”€ CrÃ©er simulateur/estimateur hardware
   â”œâ”€ Valider prÃ©dictions hardware
   â””â”€ IntÃ©grer dans loop de recherche

4. Search Algorithm Selection
   â”œâ”€ Choisir stratÃ©gie de recherche
   â”œâ”€ Configurer algorithmes
   â””â”€ DÃ©finir critÃ¨res d'arrÃªt

5. Search Execution
   â”œâ”€ ItÃ©rer: gÃ©nÃ©rer architecture
   â”œâ”€ Ã‰valuer: accuracy + hardware metrics
   â”œâ”€ Mettre Ã  jour: stratÃ©gie de recherche
   â””â”€ RÃ©pÃ©ter jusqu'Ã  convergence

6. Architecture Selection
   â”œâ”€ Analyser rÃ©sultats (Pareto front)
   â”œâ”€ SÃ©lectionner architecture(s) finale(s)
   â””â”€ Validation complÃ¨te

7. Deployment
   â”œâ”€ EntraÃ®nement complet architecture sÃ©lectionnÃ©e
   â”œâ”€ DÃ©ploiement sur hardware cible
   â””â”€ Validation en conditions rÃ©elles
"""
        return workflow
    
    def display_workflow(self):
        """Affiche le workflow"""
        print(self.generate_workflow())

workflow = NASWorkflow()
workflow.display_workflow()
```

---

## Exercices

### Exercice 16.1.1
Concevez un espace de recherche pour un MLP avec contraintes de latence < 1 Î¼s sur FPGA.

### Exercice 16.1.2
ImplÃ©mentez une fonction d'Ã©valuation qui combine accuracy et latence avec des poids configurables.

---

## Points ClÃ©s Ã  Retenir

> ğŸ“Œ **NAS automatise la recherche d'architectures optimales**

> ğŸ“Œ **Composants clÃ©s: Search Space, Search Strategy, Performance Estimation**

> ğŸ“Œ **Hardware-Aware NAS Ã©tend NAS avec mÃ©triques hardware**

> ğŸ“Œ **ProblÃ¨me multi-objectif: accuracy vs latence/Ã©nergie/ressources**

> ğŸ“Œ **Workflow standard: dÃ©finition â†’ recherche â†’ sÃ©lection â†’ dÃ©ploiement**

---

*Section suivante : [16.2 MÃ©triques Hardware](./16_02_Metriques.md)*

