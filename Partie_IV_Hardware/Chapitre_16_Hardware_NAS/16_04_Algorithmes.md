# 16.4 Algorithmes de Recherche Efficaces

---

## Introduction

Les **algorithmes de recherche efficaces** sont cruciaux pour le Hardware-Aware NAS, car l'espace de recherche est souvent tr√®s large et chaque √©valuation d'architecture est co√ªteuse (entra√Ænement partiel, simulation hardware).

Cette section pr√©sente diff√©rents algorithmes de recherche optimis√©s pour Hardware-Aware NAS, depuis les m√©thodes basiques jusqu'aux approches avanc√©es qui minimisent le nombre d'√©valuations n√©cessaires.

---

## Classification des Algorithmes

### Vue d'Ensemble

```python
class SearchAlgorithmTaxonomy:
    """
    Taxonomie des algorithmes de recherche NAS
    """
    
    def __init__(self):
        self.taxonomy = {
            'black_box': {
                'description': 'Algorithmes qui traitent l\'architecture comme bo√Æte noire',
                'examples': ['Random Search', 'Grid Search', 'Evolutionary', 'Bayesian Optimization'],
                'pros': ['G√©n√©ral', 'Pas besoin de gradients', 'Robuste'],
                'cons': ['Peut n√©cessiter beaucoup d\'√©valuations', 'Pas de guidance directe'],
                'complexity': 'O(n_evaluations √ó eval_cost)'
            },
            'gradient_based': {
                'description': 'Algorithmes diff√©rentiables',
                'examples': ['DARTS', 'ProxylessNAS', 'SNAS'],
                'pros': ['Rapide', 'Efficace', 'Gradient-based optimization'],
                'cons': ['Limit√© √† certains espaces', 'Approximation continue'],
                'complexity': 'O(training_epochs √ó forward_pass)'
            },
            'reinforcement_learning': {
                'description': 'RL pour guider la recherche',
                'examples': ['NASNet', 'ENAS', 'PNAS'],
                'pros': ['Apprentissage de strat√©gies', 'Peut √™tre efficace'],
                'cons': ['Complexe', 'Beaucoup d\'√©valuations', 'Instable'],
                'complexity': 'O(episodes √ó eval_cost)'
            },
            'performance_predictor': {
                'description': 'Utilise pr√©dicteur ML pour guider la recherche',
                'examples': ['BANANAS', 'NPENAS'],
                'pros': ['Tr√®s rapide une fois pr√©dicteur entra√Æn√©', 'Peut guider efficacement'],
                'cons': ['N√©cessite donn√©es d\'entra√Ænement', 'D√©pend de la qualit√© du pr√©dicteur'],
                'complexity': 'O(n_predictions + n_train_evaluations)'
            },
            'weight_sharing': {
                'description': 'Partage des poids entre architectures',
                'examples': ['ENAS', 'One-Shot NAS', 'SPOS'],
                'pros': ['Efficace', 'Une seule fois l\'entra√Ænement'],
                'cons': ['Approximation', 'Biais potentiel'],
                'complexity': 'O(supernet_training + n_architectures)'
            }
        }
    
    def display_taxonomy(self):
        """Affiche la taxonomie"""
        print("\n" + "="*70)
        print("Taxonomie des Algorithmes de Recherche")
        print("="*70)
        
        for category, info in self.taxonomy.items():
            print(f"\n{category.replace('_', ' ').title()}:")
            print(f"  Description: {info['description']}")
            print(f"  Exemples: {', '.join(info['examples'])}")
            print(f"  Pros:")
            for pro in info['pros']:
                print(f"    + {pro}")
            print(f"  Cons:")
            for con in info['cons']:
                print(f"    - {con}")
            print(f"  Complexity: {info['complexity']}")

taxonomy = SearchAlgorithmTaxonomy()
taxonomy.display_taxonomy()
```

---

## Random Search avec Filtrage Hardware

### Baseline Am√©lior√©

```python
import torch
import torch.nn as nn
import numpy as np
from typing import List, Dict, Tuple, Optional
import random

class FilteredRandomSearch:
    """
    Random Search avec filtrage hardware pour efficacit√©
    """
    
    def __init__(self, search_space, hardware_evaluator, constraints: Dict):
        """
        Args:
            search_space: ConstrainedSearchSpace
            hardware_evaluator: HardwareEvaluator
            constraints: Contraintes hardware
        """
        self.search_space = search_space
        self.hardware_eval = hardware_evaluator
        self.constraints = constraints
        
        # Historique de recherche
        self.evaluation_history = []
        self.valid_architectures = []
    
    def search(self, n_iterations: int = 100, input_shape: Tuple = (1, 784)) -> Dict:
        """
        Recherche random avec filtrage
        
        Returns:
            Meilleure architecture trouv√©e avec m√©triques
        """
        best_arch = None
        best_score = float('-inf')
        
        for iteration in range(n_iterations):
            # G√©n√©rer configuration
            config = self.search_space.sample_valid_config(max_attempts=50, input_shape=input_shape)
            
            if config is None:
                continue  # Aucune config valide trouv√©e
            
            # Cr√©er mod√®le
            model = self.search_space.create_model_from_config(config, input_shape[1])
            
            # V√©rifier contraintes
            is_valid, metrics = self.search_space.check_hardware_constraints(model, input_shape)
            
            if not is_valid:
                continue
            
            # √âvaluer performance (proxy rapide)
            performance = self._evaluate_performance_proxy(model, input_shape)
            
            # Score combin√© (performance - p√©nalit√©s hardware)
            score = self._compute_score(performance, metrics)
            
            # Enregistrer
            self.evaluation_history.append({
                'config': config,
                'performance': performance,
                'metrics': metrics,
                'score': score
            })
            
            if score > best_score:
                best_score = score
                best_arch = {
                    'config': config,
                    'model': model,
                    'performance': performance,
                    'metrics': metrics,
                    'score': score
                }
            
            if (iteration + 1) % 10 == 0:
                print(f"Iteration {iteration+1}/{n_iterations}: Best score = {best_score:.4f}")
        
        return best_arch
    
    def _evaluate_performance_proxy(self, model: nn.Module, input_shape: Tuple) -> float:
        """
        Proxy rapide pour estimer la performance
        (en pratique, utiliser entra√Ænement partiel ou pr√©dicteur)
        """
        # Proxy simplifi√©: corr√©lation avec nombre de param√®tres
        n_params = sum(p.numel() for p in model.parameters())
        
        # Approximation: plus de param√®tres = meilleure performance (jusqu'√† un point)
        proxy = min(0.7 + (n_params / 1e6) * 0.2, 0.95)
        
        return proxy
    
    def _compute_score(self, performance: float, metrics: Dict) -> float:
        """
        Score combin√©: performance - p√©nalit√©s hardware
        """
        # P√©nalit√©s normalis√©es
        latency_penalty = (metrics['latency_us'] / 100.0) * 0.2  # r√©f√©rence: 100 Œºs
        energy_penalty = (metrics['energy_nj'] / 1000.0) * 0.1  # r√©f√©rence: 1000 nJ
        size_penalty = (metrics['model_size_mb'] / 10.0) * 0.1  # r√©f√©rence: 10 MB
        
        score = performance - latency_penalty - energy_penalty - size_penalty
        return score
```

---

## Evolutionary Search avec Contraintes Hardware

### Algorithme √âvolutionnaire Optimis√©

```python
class ConstrainedEvolutionarySearch:
    """
    Recherche √©volutionnaire avec contraintes hardware
    """
    
    def __init__(self, search_space, hardware_evaluator, constraints: Dict):
        self.search_space = search_space
        self.hardware_eval = hardware_evaluator
        self.constraints = constraints
        
        self.population = []
        self.evaluation_history = []
    
    def search(self, population_size: int = 20, n_generations: int = 50,
               mutation_rate: float = 0.3, crossover_rate: float = 0.5,
               input_shape: Tuple = (1, 784)) -> Dict:
        """
        Recherche √©volutionnaire
        
        Args:
            population_size: Taille de la population
            n_generations: Nombre de g√©n√©rations
            mutation_rate: Probabilit√© de mutation
            crossover_rate: Probabilit√© de croisement
        """
        # Initialisation: population al√©atoire valide
        print("Initialisation de la population...")
        self.population = []
        for i in range(population_size):
            config = self.search_space.sample_valid_config(max_attempts=100, input_shape=input_shape)
            if config:
                model = self.search_space.create_model_from_config(config, input_shape[1])
                _, metrics = self.search_space.check_hardware_constraints(model, input_shape)
                performance = self._evaluate_performance_proxy(model, input_shape)
                score = self._compute_score(performance, metrics)
                
                self.population.append({
                    'config': config,
                    'score': score,
                    'metrics': metrics,
                    'performance': performance
                })
        
        print(f"Population initiale: {len(self.population)} individus valides")
        
        # √âvolution
        for generation in range(n_generations):
            # √âvaluation
            scores = [ind['score'] for ind in self.population]
            
            # S√©lection (top 50% + quelques random)
            sorted_pop = sorted(self.population, key=lambda x: x['score'], reverse=True)
            elite_size = population_size // 2
            elite = sorted_pop[:elite_size]
            
            # Nouvelle g√©n√©ration
            new_population = elite.copy()
            
            # G√©n√©rer enfants
            while len(new_population) < population_size:
                # S√©lection de parents (tournament selection)
                parent1 = self._tournament_selection(elite, tournament_size=3)
                parent2 = self._tournament_selection(elite, tournament_size=3)
                
                # Croisement
                if random.random() < crossover_rate:
                    child_config = self._crossover(parent1['config'], parent2['config'])
                else:
                    child_config = parent1['config'].copy()
                
                # Mutation
                if random.random() < mutation_rate:
                    child_config = self._mutate(child_config)
                
                # Validation et √©valuation
                model = self.search_space.create_model_from_config(child_config, input_shape[1])
                is_valid, metrics = self.search_space.check_hardware_constraints(model, input_shape)
                
                if is_valid:
                    performance = self._evaluate_performance_proxy(model, input_shape)
                    score = self._compute_score(performance, metrics)
                    
                    new_population.append({
                        'config': child_config,
                        'score': score,
                        'metrics': metrics,
                        'performance': performance
                    })
            
            self.population = new_population
            
            best = max(self.population, key=lambda x: x['score'])
            print(f"Generation {generation+1}/{n_generations}: Best score = {best['score']:.4f}, "
                  f"Latency = {best['metrics']['latency_us']:.2f} Œºs")
        
        # Retourner meilleure solution
        best = max(self.population, key=lambda x: x['score'])
        model = self.search_space.create_model_from_config(best['config'], input_shape[1])
        return {
            'config': best['config'],
            'model': model,
            'score': best['score'],
            'metrics': best['metrics'],
            'performance': best['performance']
        }
    
    def _tournament_selection(self, population: List[Dict], tournament_size: int = 3) -> Dict:
        """S√©lection par tournoi"""
        tournament = random.sample(population, min(tournament_size, len(population)))
        return max(tournament, key=lambda x: x['score'])
    
    def _crossover(self, parent1: Dict, parent2: Dict) -> Dict:
        """Croisement de deux configurations"""
        child = parent1.copy()
        
        # Croisement: moyenne pour valeurs num√©riques, choix pour cat√©gorielles
        if 'num_layers' in child:
            child['num_layers'] = (parent1['num_layers'] + parent2['num_layers']) // 2
        
        if 'layer_widths' in child and 'layer_widths' in parent2:
            # Prendre largeurs altern√©es
            widths1 = parent1.get('layer_widths', [])
            widths2 = parent2.get('layer_widths', [])
            max_len = max(len(widths1), len(widths2))
            child_widths = []
            for i in range(max_len):
                if i % 2 == 0 and i < len(widths1):
                    child_widths.append(widths1[i])
                elif i < len(widths2):
                    child_widths.append(widths2[i])
            child['layer_widths'] = child_widths[:child['num_layers']]
        
        if 'activation' in child:
            child['activation'] = random.choice([parent1['activation'], parent2['activation']])
        
        return child
    
    def _mutate(self, config: Dict) -> Dict:
        """Mutation d'une configuration"""
        mutated = config.copy()
        
        # Mutation al√©atoire d'un param√®tre
        param_to_mutate = random.choice(list(mutated.keys()))
        
        if param_to_mutate == 'num_layers':
            mutated['num_layers'] = random.choice(self.search_space.base_space['num_layers'])
        elif param_to_mutate == 'layer_widths':
            mutated['layer_widths'] = [random.choice(self.search_space.base_space['layer_widths'])]
        elif param_to_mutate == 'activation':
            mutated['activation'] = random.choice(self.search_space.base_space['activation'])
        elif param_to_mutate == 'use_batch_norm':
            mutated['use_batch_norm'] = not mutated['use_batch_norm']
        
        return mutated
    
    def _evaluate_performance_proxy(self, model: nn.Module, input_shape: Tuple) -> float:
        """Proxy de performance"""
        n_params = sum(p.numel() for p in model.parameters())
        return min(0.7 + (n_params / 1e6) * 0.2, 0.95)
    
    def _compute_score(self, performance: float, metrics: Dict) -> float:
        """Score combin√©"""
        latency_penalty = (metrics['latency_us'] / 100.0) * 0.2
        energy_penalty = (metrics['energy_nj'] / 1000.0) * 0.1
        return performance - latency_penalty - energy_penalty
```

---

## Bayesian Optimization avec Pr√©dicteur Hardware

### Optimisation Bay√©sienne Efficace

```python
class BayesianOptimizationNAS:
    """
    Bayesian Optimization pour Hardware-Aware NAS
    
    Utilise un mod√®le probabiliste (Gaussian Process) pour guider la recherche
    """
    
    def __init__(self, search_space, hardware_evaluator, constraints: Dict):
        self.search_space = search_space
        self.hardware_eval = hardware_evaluator
        self.constraints = constraints
        
        # Historique d'observations
        self.X_observed = []  # Configurations
        self.y_observed = []  # Scores
        
        # En pratique, utiliser sklearn.gaussian_process ou GPyTorch
        self.gp_model = None
    
    def search(self, n_iterations: int = 50, n_initial: int = 10,
               input_shape: Tuple = (1, 784)) -> Dict:
        """
        Recherche par optimisation bay√©sienne
        
        Args:
            n_iterations: Nombre d'it√©rations
            n_initial: Nombre d'√©valuations initiales (random)
        """
        # Phase d'exploration initiale
        print(f"Phase d'exploration initiale ({n_initial} √©valuations)...")
        for i in range(n_initial):
            config = self.search_space.sample_valid_config(max_attempts=50, input_shape=input_shape)
            if config:
                score = self._evaluate_config(config, input_shape)
                self.X_observed.append(self._config_to_vector(config))
                self.y_observed.append(score)
        
        # Phase d'optimisation bay√©sienne
        print(f"Phase d'optimisation bay√©sienne ({n_iterations} it√©rations)...")
        for iteration in range(n_iterations):
            # Entra√Æner mod√®le GP (simplifi√© ici)
            # En pratique: self.gp_model.fit(self.X_observed, self.y_observed)
            
            # Acquisition function: choisir prochain point √† √©valuer
            # En pratique: utiliser Expected Improvement (EI) ou Upper Confidence Bound (UCB)
            next_config = self._acquisition_function_maximization()
            
            # √âvaluer
            score = self._evaluate_config(next_config, input_shape)
            self.X_observed.append(self._config_to_vector(next_config))
            self.y_observed.append(score)
            
            best_idx = np.argmax(self.y_observed)
            best_score = self.y_observed[best_idx]
            
            if (iteration + 1) % 5 == 0:
                print(f"Iteration {iteration+1}/{n_iterations}: Best score = {best_score:.4f}")
        
        # Retourner meilleure solution
        best_idx = np.argmax(self.y_observed)
        best_vector = self.X_observed[best_idx]
        best_config = self._vector_to_config(best_vector)
        model = self.search_space.create_model_from_config(best_config, input_shape[1])
        _, metrics = self.search_space.check_hardware_constraints(model, input_shape)
        
        return {
            'config': best_config,
            'model': model,
            'score': self.y_observed[best_idx],
            'metrics': metrics
        }
    
    def _evaluate_config(self, config: Dict, input_shape: Tuple) -> float:
        """√âvalue une configuration"""
        model = self.search_space.create_model_from_config(config, input_shape[1])
        is_valid, metrics = self.search_space.check_hardware_constraints(model, input_shape)
        
        if not is_valid:
            return -float('inf')  # P√©nalit√© forte
        
        performance = self._evaluate_performance_proxy(model, input_shape)
        score = self._compute_score(performance, metrics)
        return score
    
    def _acquisition_function_maximization(self) -> Dict:
        """
        Maximise la fonction d'acquisition pour choisir le prochain point
        
        En pratique, utiliser Expected Improvement avec GP
        Ici: approximation simple avec exploration/exploitation
        """
        # Simplification: combinaison exploration al√©atoire et exploitation
        if len(self.y_observed) < 5:
            # Plus d'exploration au d√©but
            return self.search_space.sample_valid_config(max_attempts=50, input_shape=(1, 784))
        else:
            # Exploitation: chercher autour des bonnes solutions
            best_idx = np.argmax(self.y_observed)
            best_vector = self.X_observed[best_idx]
            best_config = self._vector_to_config(best_vector)
            
            # Mutation locale
            mutated = self._mutate_local(best_config)
            return mutated
    
    def _mutate_local(self, config: Dict) -> Dict:
        """Mutation locale pour exploitation"""
        mutated = config.copy()
        
        # Petite mutation
        if random.random() < 0.5 and 'num_layers' in mutated:
            current = mutated['num_layers']
            options = [max(3, current-1), current, min(8, current+1)]
            mutated['num_layers'] = random.choice(options)
        
        return mutated
    
    def _config_to_vector(self, config: Dict) -> np.ndarray:
        """Convertit config en vecteur num√©rique"""
        # Encodage simple (en pratique, utiliser one-hot ou embedding)
        vector = [
            config.get('num_layers', 5) / 10.0,  # normalis√©
            len(config.get('layer_widths', [])) / 10.0,
            1.0 if config.get('use_batch_norm', False) else 0.0,
            1.0 if config.get('use_dropout', False) else 0.0
        ]
        return np.array(vector)
    
    def _vector_to_config(self, vector: np.ndarray) -> Dict:
        """Convertit vecteur en config"""
        # D√©codage (approximation)
        config = {
            'num_layers': int(vector[0] * 10),
            'layer_widths': [128] * int(vector[1] * 10),
            'use_batch_norm': bool(vector[2] > 0.5),
            'use_dropout': bool(vector[3] > 0.5),
            'activation': 'relu',
            'dropout_rate': 0.2
        }
        return config
    
    def _evaluate_performance_proxy(self, model: nn.Module, input_shape: Tuple) -> float:
        """Proxy de performance"""
        n_params = sum(p.numel() for p in model.parameters())
        return min(0.7 + (n_params / 1e6) * 0.2, 0.95)
    
    def _compute_score(self, performance: float, metrics: Dict) -> float:
        """Score combin√©"""
        latency_penalty = (metrics['latency_us'] / 100.0) * 0.2
        return performance - latency_penalty
```

---

## Differentiable Architecture Search (DARTS) avec Hardware

### NAS Diff√©rentiable Adapt√©

```python
class HardwareAwareDARTS:
    """
    DARTS (Differentiable Architecture Search) adapt√© pour hardware
    
    Optimise simultan√©ment les poids du mod√®le et l'architecture
    """
    
    def __init__(self, search_space, hardware_evaluator, constraints: Dict):
        self.search_space = search_space
        self.hardware_eval = hardware_evaluator
        self.constraints = constraints
        
        # Param√®tres d'architecture alpha (√† optimiser)
        self.alpha = None
    
    def search(self, train_loader, val_loader, epochs: int = 50,
               w_lr: float = 3e-4, alpha_lr: float = 3e-4) -> Dict:
        """
        Recherche diff√©rentiable
        
        Args:
            train_loader: DataLoader pour entra√Ænement
            val_loader: DataLoader pour validation
            epochs: Nombre d'epochs
            w_lr: Learning rate pour poids
            alpha_lr: Learning rate pour alpha
        """
        import torch.optim as optim
        import torch.nn.functional as F
        
        # Initialiser alpha (param√®tres d'architecture)
        # En pratique, alpha d√©finit les poids des op√©rations dans le super-net
        # Simplifi√© ici
        self.alpha = nn.Parameter(torch.randn(8, 4))  # 8 op√©rations, 4 edges
        
        # Cr√©er super-net (mod√®le avec toutes les op√©rations)
        supernet = self._create_supernet()
        
        # Optimiseurs
        w_optimizer = optim.Adam(supernet.parameters(), lr=w_lr)
        alpha_optimizer = optim.Adam([self.alpha], lr=alpha_lr)
        
        criterion = nn.CrossEntropyLoss()
        
        for epoch in range(epochs):
            # Phase 1: Entra√Æner les poids du mod√®le
            supernet.train()
            for batch_idx, (data, target) in enumerate(train_loader):
                w_optimizer.zero_grad()
                
                # Forward avec architecture actuelle
                output = self._forward_with_alpha(supernet, data, self.alpha)
                
                loss = criterion(output, target)
                loss.backward()
                w_optimizer.step()
            
            # Phase 2: Optimiser alpha sur validation set
            supernet.eval()
            val_loss = 0
            for data, target in val_loader:
                alpha_optimizer.zero_grad()
                
                output = self._forward_with_alpha(supernet, data, self.alpha)
                loss = criterion(output, target)
                
                # Ajouter p√©nalit√© hardware
                if epoch > 10:  # Commencer apr√®s quelques epochs
                    hardware_penalty = self._compute_hardware_penalty(supernet)
                    loss = loss + 0.1 * hardware_penalty
                
                loss.backward()
                alpha_optimizer.step()
                
                val_loss += loss.item()
            
            if (epoch + 1) % 10 == 0:
                print(f"Epoch {epoch+1}/{epochs}: Val loss = {val_loss/len(val_loader):.4f}")
        
        # D√©river architecture finale depuis alpha
        final_arch = self._derive_architecture()
        
        return {
            'architecture': final_arch,
            'alpha': self.alpha.detach().numpy()
        }
    
    def _create_supernet(self) -> nn.Module:
        """
        Cr√©e un super-net avec toutes les op√©rations possibles
        """
        # Simplifi√©: en pratique, cr√©er un DAG avec toutes les op√©rations
        return nn.Sequential(
            nn.Linear(784, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 10)
        )
    
    def _forward_with_alpha(self, model: nn.Module, x: torch.Tensor, alpha: torch.Tensor) -> torch.Tensor:
        """
        Forward pass avec architecture pond√©r√©e par alpha
        """
        # Simplifi√©: en pratique, utiliser softmax sur alpha et m√©langer op√©rations
        # Ici: forward standard
        return model(x)
    
    def _compute_hardware_penalty(self, model: nn.Module) -> torch.Tensor:
        """
        Calcule p√©nalit√© hardware pour guider la recherche
        """
        # √âvaluer m√©triques hardware (approximation)
        metrics = self.hardware_eval.evaluate_architecture(model, (1, 784))
        
        # P√©nalit√© normalis√©e
        latency_penalty = torch.tensor(metrics['latency_us'] / 100.0)
        energy_penalty = torch.tensor(metrics['energy_nj'] / 1000.0)
        
        return latency_penalty + energy_penalty
    
    def _derive_architecture(self) -> Dict:
        """
        D√©rive l'architecture discr√®te depuis alpha
        """
        # Prendre op√©rations avec alpha le plus √©lev√©
        # Simplifi√© ici
        return {'num_layers': 4, 'width': 128}
```

---

## Comparaison des Algorithmes

### Benchmark

```python
class AlgorithmComparison:
    """
    Compare diff√©rents algorithmes de recherche
    """
    
    def __init__(self, search_space, hardware_evaluator, constraints: Dict):
        self.search_space = search_space
        self.hardware_eval = hardware_evaluator
        self.constraints = constraints
    
    def compare_algorithms(self, n_evaluations: int = 100, input_shape: Tuple = (1, 784)) -> Dict:
        """
        Compare plusieurs algorithmes
        """
        results = {}
        
        # Random Search
        print("\n" + "="*70)
        print("Random Search")
        print("="*70)
        random_search = FilteredRandomSearch(self.search_space, self.hardware_eval, self.constraints)
        random_result = random_search.search(n_iterations=n_evaluations, input_shape=input_shape)
        results['random'] = {
            'best_score': random_result['score'] if random_result else -float('inf'),
            'n_evaluations': n_evaluations
        }
        
        # Evolutionary
        print("\n" + "="*70)
        print("Evolutionary Search")
        print("="*70)
        evo_search = ConstrainedEvolutionarySearch(self.search_space, self.hardware_eval, self.constraints)
        evo_result = evo_search.search(population_size=20, n_generations=n_evaluations//20, input_shape=input_shape)
        results['evolutionary'] = {
            'best_score': evo_result['score'],
            'n_evaluations': n_evaluations
        }
        
        # Bayesian Optimization
        print("\n" + "="*70)
        print("Bayesian Optimization")
        print("="*70)
        bo_search = BayesianOptimizationNAS(self.search_space, self.hardware_eval, self.constraints)
        bo_result = bo_search.search(n_iterations=n_evaluations//2, n_initial=10, input_shape=input_shape)
        results['bayesian'] = {
            'best_score': bo_result['score'],
            'n_evaluations': n_evaluations//2 + 10
        }
        
        # Afficher comparaison
        print("\n" + "="*70)
        print("Comparaison des Algorithmes")
        print("="*70)
        
        for algo_name, result in results.items():
            print(f"\n{algo_name.upper()}:")
            print(f"  Best score: {result['best_score']:.4f}")
            print(f"  Evaluations: {result['n_evaluations']}")
            print(f"  Efficiency (score/eval): {result['best_score']/result['n_evaluations']:.6f}")
        
        return results
```

---

## Exercices

### Exercice 16.4.1
Impl√©mentez une version am√©lior√©e de Random Search qui utilise un pr√©dicteur de performance pour filtrer les architectures prometteuses.

### Exercice 16.4.2
Comparez les performances de Random Search, Evolutionary Search et Bayesian Optimization sur un espace de recherche donn√© avec contraintes hardware.

### Exercice 16.4.3
Adaptez DARTS pour inclure des p√©nalit√©s hardware dans la fonction objectif et comparez avec version sans p√©nalit√©s.

### Exercice 16.4.4
Impl√©mentez un algorithme hybride qui combine Random Search (exploration) et Evolutionary Search (exploitation).

---

## Points Cl√©s √† Retenir

> üìå **Random Search est une baseline simple mais peut √™tre efficace avec filtrage hardware**

> üìå **Evolutionary Search est robuste et bien adapt√© aux espaces discrets avec contraintes**

> üìå **Bayesian Optimization est efficace pour espaces continus et n√©cessite peu d'√©valuations**

> üìå **DARTS est tr√®s rapide mais limit√© √† certains espaces et n√©cessite adaptation pour hardware**

> üìå **Le choix de l'algorithme d√©pend du budget d'√©valuations et du type d'espace de recherche**

> üìå **Les algorithmes hybrides peuvent combiner les avantages de diff√©rentes approches**

---

*Section pr√©c√©dente : [16.3 Espaces de Recherche Contraints](./16_03_Espaces.md) | Section suivante : [16.5 Co-design Mod√®le-Hardware](./16_05_CoDesign.md)*

