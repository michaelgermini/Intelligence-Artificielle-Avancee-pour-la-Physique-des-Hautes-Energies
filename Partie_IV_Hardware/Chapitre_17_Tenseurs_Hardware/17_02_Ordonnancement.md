# 17.2 Ordonnancement Optimal des Contractions

---

## Introduction

L'**ordonnancement des contractions** est crucial pour l'efficacit√© des r√©seaux de tenseurs. Pour un r√©seau avec N tenseurs, il existe O(2^N) ordonnancements possibles, et le choix de l'ordonnancement peut changer la complexit√© computationnelle et l'utilisation m√©moire de plusieurs ordres de grandeur.

Cette section pr√©sente les algorithmes pour trouver l'ordonnancement optimal, incluant la recherche exhaustive, les heuristiques gloutonnes, et les m√©thodes d'optimisation dynamique.

---

## Probl√®me d'Ordonnancement

### D√©finition

```python
import numpy as np
from typing import List, Tuple, Dict
import itertools

class ContractionScheduling:
    """
    Ordonnancement de contractions tensorielles
    """
    
    def __init__(self):
        self.problem_definition = """
        Probl√®me d'ordonnancement:
        
        √âtant donn√© un ensemble de tenseurs {T‚ÇÅ, T‚ÇÇ, ..., T‚Çô},
        trouver un ordre de contractions qui minimise:
        
        1. Complexit√© computationnelle totale
        2. M√©moire maximale utilis√©e
        3. Latence totale
        
        Contraintes:
        - Chaque tenseur doit √™tre contract√© exactement une fois
        - Indices contract√©s doivent correspondre
        """
    
    def contraction_tree_example(self):
        """
        Exemple d'arbre de contraction
        """
        # Exemple: 4 tenseurs A, B, C, D
        # Contractions possibles: ((A*B)*C)*D ou (A*B)*(C*D) ou A*((B*C)*D)
        
        trees = {
            'left_associative': {
                'order': '((A*B)*C)*D',
                'description': 'Association √† gauche',
                'memory_peak': 'Peut √™tre √©lev√©e si r√©sultat cro√Æt rapidement'
            },
            'right_associative': {
                'order': 'A*(B*(C*D))',
                'description': 'Association √† droite',
                'memory_peak': 'Peut diff√©rer selon tailles'
            },
            'balanced': {
                'order': '(A*B)*(C*D)',
                'description': 'Arbre √©quilibr√©',
                'memory_peak': 'Souvent meilleur compromis'
            }
        }
        
        return trees

scheduling = ContractionScheduling()
print(scheduling.problem_definition)
```

---

## Complexit√© des Contractions

### Analyse de Complexit√©

```python
class ContractionComplexity:
    """
    Analyse de complexit√© des contractions
    """
    
    def compute_contraction_complexity(self, shape_A: Tuple, shape_B: Tuple, 
                                      contracted_dims_A: List[int], 
                                      contracted_dims_B: List[int]) -> Dict:
        """
        Calcule la complexit√© d'une contraction
        
        Returns:
            dict avec complexit√© computationnelle et m√©moire
        """
        # Dimensions libres de A
        free_dims_A = [i for i in range(len(shape_A)) if i not in contracted_dims_A]
        free_dims_B = [i for i in range(len(shape_B)) if i not in contracted_dims_B]
        
        # Taille des dimensions contract√©es
        contracted_size_A = np.prod([shape_A[i] for i in contracted_dims_A])
        contracted_size_B = np.prod([shape_B[i] for i in contracted_dims_B])
        
        # V√©rifier compatibilit√©
        if contracted_size_A != contracted_size_B:
            raise ValueError("Dimensions contract√©es incompatibles")
        
        # Taille des dimensions libres
        free_size_A = np.prod([shape_A[i] for i in free_dims_A])
        free_size_B = np.prod([shape_B[i] for i in free_dims_B])
        
        # Shape du r√©sultat
        result_shape = tuple([shape_A[i] for i in free_dims_A] + 
                           [shape_B[i] for i in free_dims_B])
        result_size = np.prod(result_shape)
        
        # Complexit√© computationnelle: O(free_A √ó free_B √ó contracted)
        computation_ops = free_size_A * free_size_B * contracted_size_A
        
        # M√©moire: tenseurs d'input + r√©sultat
        memory_input = np.prod(shape_A) + np.prod(shape_B)
        memory_output = result_size
        memory_peak = memory_input + memory_output  # Pendant contraction
        
        return {
            'computation_ops': computation_ops,
            'memory_input': memory_input,
            'memory_output': memory_output,
            'memory_peak': memory_peak,
            'result_shape': result_shape
        }
    
    def compare_contraction_orders(self, tensors: List[Tuple], contraction_orders: List[List[Tuple]]):
        """
        Compare diff√©rents ordres de contractions
        
        Args:
            tensors: Liste de shapes des tenseurs initiaux
            contraction_orders: Liste d'ordres (chaque ordre = liste de paires (i, j))
        """
        results = []
        
        for order_idx, order in enumerate(contraction_orders):
            total_ops = 0
            peak_memory = 0
            current_tensors = list(tensors)
            
            for step, (i, j) in enumerate(order):
                # Simplifi√©: suppose contraction standard sur derni√®res/premi√®res dims
                shape_A = current_tensors[i]
                shape_B = current_tensors[j]
                
                # Approximation: contracter derni√®re dim de A avec premi√®re de B
                contracted_dims_A = [len(shape_A) - 1] if len(shape_A) > 0 else []
                contracted_dims_B = [0] if len(shape_B) > 0 else []
                
                complexity = self.compute_contraction_complexity(
                    shape_A, shape_B, contracted_dims_A, contracted_dims_B
                )
                
                total_ops += complexity['computation_ops']
                peak_memory = max(peak_memory, complexity['memory_peak'])
                
                # Mettre √† jour: remplacer i et j par r√©sultat
                new_shape = complexity['result_shape']
                current_tensors = ([current_tensors[k] for k in range(len(current_tensors)) 
                                  if k not in [i, j]] + [new_shape])
            
            results.append({
                'order': order,
                'total_ops': total_ops,
                'peak_memory': peak_memory
            })
        
        return results

# Exemple
complexity_analyzer = ContractionComplexity()

# Exemple: 3 tenseurs
tensors = [(10, 20), (20, 30), (30, 40)]

# Ordre 1: ((A*B)*C)
order1 = [(0, 1), (0, 1)]  # (A*B), puis r√©sultat*C
# Ordre 2: (A*(B*C))
order2 = [(1, 2), (0, 1)]  # (B*C), puis A*r√©sultat

results = complexity_analyzer.compare_contraction_orders(tensors, [order1, order2])

print("\n" + "="*70)
print("Comparaison d'Ordonnancements")
print("="*70)
for i, result in enumerate(results):
    print(f"\nOrdre {i+1}:")
    print(f"  Op√©rations totales: {result['total_ops']:,}")
    print(f"  M√©moire peak: {result['peak_memory']:,} √©l√©ments")
```

---

## Algorithmes d'Ordonnancement

### Recherche Exhaustive (Petit N)

```python
class ExhaustiveScheduler:
    """
    Recherche exhaustive de l'ordonnancement optimal
    """
    
    def __init__(self, max_tensors=8):
        """
        Args:
            max_tensors: Nombre maximum de tenseurs pour recherche exhaustive
        """
        self.max_tensors = max_tensors
    
    def generate_all_orders(self, n_tensors: int) -> List[List[Tuple]]:
        """
        G√©n√®re tous les ordres possibles de contractions
        
        Pour N tenseurs, il y a (2N-2)! / (N-1)! ordres possibles
        """
        if n_tensors > self.max_tensors:
            raise ValueError(f"Trop de tenseurs pour recherche exhaustive (max {self.max_tensors})")
        
        # G√©n√©ration r√©cursive de tous les arbres binaires
        orders = []
        
        def generate_recursive(remaining: List[int], current_order: List[Tuple]):
            if len(remaining) == 1:
                orders.append(current_order.copy())
                return
            
            # Essayer toutes les paires possibles
            for i in range(len(remaining)):
                for j in range(i + 1, len(remaining)):
                    # Nouvelle paire
                    new_pair = (remaining[i], remaining[j])
                    
                    # Nouveaux indices (remplacer i, j par nouveau)
                    new_remaining = ([remaining[k] for k in range(len(remaining)) 
                                    if k not in [i, j]] + [len(current_order)])
                    
                    # Nouvel ordre
                    new_order = current_order + [new_pair]
                    
                    generate_recursive(new_remaining, new_order)
        
        initial_indices = list(range(n_tensors))
        generate_recursive(initial_indices, [])
        
        return orders
    
    def find_optimal_order(self, tensors: List[Tuple], 
                          objective='computation') -> Dict:
        """
        Trouve l'ordonnancement optimal par recherche exhaustive
        
        Args:
            tensors: Liste de shapes des tenseurs
            objective: 'computation', 'memory', ou 'combined'
        """
        n = len(tensors)
        
        if n > self.max_tensors:
            raise ValueError(f"Trop de tenseurs: {n} (max {self.max_tensors})")
        
        # G√©n√©rer tous les ordres
        all_orders = self.generate_all_orders(n)
        
        # √âvaluer chaque ordre
        complexity = ContractionComplexity()
        best_order = None
        best_score = float('inf')
        
        for order in all_orders:
            results = complexity.compare_contraction_orders(tensors, [order])
            result = results[0]
            
            # Score selon objectif
            if objective == 'computation':
                score = result['total_ops']
            elif objective == 'memory':
                score = result['peak_memory']
            else:  # combined
                # Normaliser et combiner (exemple)
                score = (result['total_ops'] / 1e6) + (result['peak_memory'] / 1e6)
            
            if score < best_score:
                best_score = score
                best_order = order
        
        return {
            'optimal_order': best_order,
            'score': best_score,
            'total_orders_evaluated': len(all_orders)
        }

# Exemple petit
exhaustive = ExhaustiveScheduler(max_tensors=5)

tensors_small = [(10, 20), (20, 30), (30, 40), (40, 50)]
optimal = exhaustive.find_optimal_order(tensors_small, objective='computation')

print(f"\nOrdre optimal trouv√©:")
print(f"  Ordre: {optimal['optimal_order']}")
print(f"  Score: {optimal['score']:.2e}")
print(f"  Ordres √©valu√©s: {optimal['total_orders_evaluated']}")
```

---

## Heuristiques Gloutonnes

### Greedy Algorithms

```python
class GreedyScheduler:
    """
    Heuristiques gloutonnes pour ordonnancement
    """
    
    def greedy_min_complexity(self, tensors: List[Tuple]) -> List[Tuple]:
        """
        Algorithme glouton: choisit contraction de complexit√© minimale √† chaque √©tape
        """
        complexity = ContractionComplexity()
        order = []
        current_tensors = list(tensors)
        current_indices = list(range(len(tensors)))
        
        while len(current_tensors) > 1:
            best_i, best_j = None, None
            best_complexity = float('inf')
            
            # Tester toutes les paires possibles
            for i in range(len(current_tensors)):
                for j in range(i + 1, len(current_tensors)):
                    shape_A = current_tensors[i]
                    shape_B = current_tensors[j]
                    
                    # Approximation: contracter derni√®res/premi√®res dims
                    contracted_dims_A = [len(shape_A) - 1] if len(shape_A) > 0 else []
                    contracted_dims_B = [0] if len(shape_B) > 0 else []
                    
                    comp = complexity.compute_contraction_complexity(
                        shape_A, shape_B, contracted_dims_A, contracted_dims_B
                    )
                    
                    if comp['computation_ops'] < best_complexity:
                        best_complexity = comp['computation_ops']
                        best_i, best_j = i, j
            
            # Effectuer contraction
            order.append((current_indices[best_i], current_indices[best_j]))
            
            # Mettre √† jour
            shape_A = current_tensors[best_i]
            shape_B = current_tensors[best_j]
            result_shape = complexity.compute_contraction_complexity(
                shape_A, shape_B, [len(shape_A)-1], [0]
            )['result_shape']
            
            # Remplacer i et j par r√©sultat
            new_tensors = ([current_tensors[k] for k in range(len(current_tensors)) 
                          if k not in [best_i, best_j]] + [result_shape])
            new_indices = ([current_indices[k] for k in range(len(current_indices)) 
                          if k not in [best_i, best_j]] + [max(current_indices) + 1])
            
            current_tensors = new_tensors
            current_indices = new_indices
        
        return order
    
    def greedy_min_memory(self, tensors: List[Tuple]) -> List[Tuple]:
        """
        Algorithme glouton: minimise m√©moire peak √† chaque √©tape
        """
        complexity = ContractionComplexity()
        order = []
        current_tensors = list(tensors)
        current_indices = list(range(len(tensors)))
        
        while len(current_tensors) > 1:
            best_i, best_j = None, None
            best_memory = float('inf')
            
            for i in range(len(current_tensors)):
                for j in range(i + 1, len(current_tensors)):
                    shape_A = current_tensors[i]
                    shape_B = current_tensors[j]
                    
                    contracted_dims_A = [len(shape_A) - 1] if len(shape_A) > 0 else []
                    contracted_dims_B = [0] if len(shape_B) > 0 else []
                    
                    comp = complexity.compute_contraction_complexity(
                        shape_A, shape_B, contracted_dims_A, contracted_dims_B
                    )
                    
                    if comp['memory_peak'] < best_memory:
                        best_memory = comp['memory_peak']
                        best_i, best_j = i, j
            
            # Effectuer contraction (m√™me logique que pr√©c√©dent)
            order.append((current_indices[best_i], current_indices[best_j]))
            
            # Mise √† jour (simplifi√©e)
            result_shape = complexity.compute_contraction_complexity(
                current_tensors[best_i], current_tensors[best_j],
                [len(current_tensors[best_i])-1], [0]
            )['result_shape']
            
            current_tensors = ([current_tensors[k] for k in range(len(current_tensors)) 
                              if k not in [best_i, best_j]] + [result_shape])
            current_indices = ([current_indices[k] for k in range(len(current_indices)) 
                              if k not in [best_i, best_j]] + [max(current_indices) + 1])
        
        return order

# Test heuristique
greedy = GreedyScheduler()

tensors = [(10, 20), (20, 30), (30, 40), (40, 50), (50, 60)]

order_comp = greedy.greedy_min_complexity(tensors)
order_mem = greedy.greedy_min_memory(tensors)

print("\n" + "="*70)
print("Heuristiques Gloutonnes")
print("="*70)
print(f"\nOrdre (min complexit√©): {order_comp}")
print(f"Ordre (min m√©moire): {order_mem}")
```

---

## Programmation Dynamique

### Optimal Substructure

```python
class DynamicProgrammingScheduler:
    """
    Ordonnancement optimal avec programmation dynamique
    """
    
    def __init__(self):
        self.memo = {}  # Cache pour r√©sultats
    
    def dp_optimal_order(self, tensor_shapes: List[Tuple], 
                        objective='computation') -> Dict:
        """
        Trouve ordre optimal avec programmation dynamique
        
        Optimal substructure: ordre optimal pour sous-ensemble = partie de ordre global optimal
        """
        n = len(tensor_shapes)
        
        # DP state: (mask, remaining_tensors)
        # mask: bits indiquant quels tenseurs restent
        
        def dp_recursive(mask: int, remaining: List[int]) -> Tuple[List[Tuple], float]:
            """
            Retourne (ordre, score) optimal pour tenseurs restants
            """
            if len(remaining) == 1:
                return [], 0.0
            
            # V√©rifier cache
            cache_key = (mask, tuple(remaining))
            if cache_key in self.memo:
                return self.memo[cache_key]
            
            complexity = ContractionComplexity()
            best_order = None
            best_score = float('inf')
            
            # Essayer toutes les paires
            for i in range(len(remaining)):
                for j in range(i + 1, len(remaining)):
                    idx_i, idx_j = remaining[i], remaining[j]
                    shape_A = tensor_shapes[idx_i]
                    shape_B = tensor_shapes[idx_j]
                    
                    # Calculer complexit√© de cette contraction
                    contracted_dims_A = [len(shape_A) - 1] if len(shape_A) > 0 else []
                    contracted_dims_B = [0] if len(shape_B) > 0 else []
                    
                    comp = complexity.compute_contraction_complexity(
                        shape_A, shape_B, contracted_dims_A, contracted_dims_B
                    )
                    
                    # Score de cette √©tape
                    if objective == 'computation':
                        step_score = comp['computation_ops']
                    elif objective == 'memory':
                        step_score = comp['memory_peak']
                    else:
                        step_score = (comp['computation_ops'] / 1e6) + (comp['memory_peak'] / 1e6)
                    
                    # Nouveaux tenseurs restants
                    new_remaining = ([remaining[k] for k in range(len(remaining)) 
                                    if k not in [i, j]] + [n + len(remaining)])  # nouveau index
                    new_mask = mask & ~((1 << idx_i) | (1 << idx_j))
                    
                    # R√©cursion
                    sub_order, sub_score = dp_recursive(new_mask, new_remaining)
                    
                    total_score = step_score + sub_score
                    
                    if total_score < best_score:
                        best_score = total_score
                        best_order = [(idx_i, idx_j)] + sub_order
            
            self.memo[cache_key] = (best_order, best_score)
            return best_order, best_score
        
        # Appel initial
        initial_mask = (1 << n) - 1  # Tous les bits √† 1
        initial_remaining = list(range(n))
        
        optimal_order, optimal_score = dp_recursive(initial_mask, initial_remaining)
        
        return {
            'optimal_order': optimal_order,
            'optimal_score': optimal_score
        }

# Exemple DP (petit pour √©viter explosion combinatoire)
dp_scheduler = DynamicProgrammingScheduler()

tensors_dp = [(10, 20), (20, 30), (30, 40), (40, 50)]

result_dp = dp_scheduler.dp_optimal_order(tensors_dp, objective='computation')

print("\n" + "="*70)
print("Programmation Dynamique")
print("="*70)
print(f"Ordre optimal: {result_dp['optimal_order']}")
print(f"Score optimal: {result_dp['optimal_score']:.2e}")
```

---

## Approximations et Bornes

### Bornes Th√©oriques

```python
class ContractionBounds:
    """
    Bornes th√©oriques sur complexit√© de contractions
    """
    
    def treewidth_bound(self, contraction_graph):
        """
        Borne bas√©e sur treewidth du graphe de contraction
        
        La complexit√© est born√©e par exp(treewidth)
        """
        # En pratique, calculer treewidth est difficile (NP-hard)
        # Mais donne borne th√©orique
        
        return {
            'bound': 'O(exp(treewidth))',
            'significance': 'Complexit√© minimale possible pour ce graphe'
        }
    
    def rank_bound(self, tensor_decomposition):
        """
        Borne bas√©e sur rang tensoriel
        
        La complexit√© est li√©e aux rangs des d√©compositions
        """
        return {
            'bound': 'O(rank^n) pour certains r√©seaux',
            'significance': 'Structure du r√©seau limite complexit√©'
        }

bounds = ContractionBounds()
```

---

## Applications Pratiques

### Optimisation pour R√©seaux Sp√©cifiques

```python
class SpecificNetworkOptimization:
    """
    Optimisations pour r√©seaux de tenseurs sp√©cifiques
    """
    
    def mps_optimal_order(self, bond_dimensions: List[int]):
        """
        Ordonnancement optimal pour MPS (Matrix Product State)
        
        MPS: cha√Æne lin√©aire, ordre naturel de gauche √† droite (ou droite √† gauche)
        """
        n = len(bond_dimensions) - 1  # n tenseurs
        
        # Ordre s√©quentiel est souvent optimal pour MPS
        order = [(i, i+1) for i in range(n-1)]
        
        return {
            'order': order,
            'complexity': 'O(n * d^3) o√π d = max bond dimension',
            'memory': 'O(d^2)'
        }
    
    def peps_heuristic_order(self, grid_shape: Tuple[int, int], bond_dims: Dict):
        """
        Heuristique pour PEPS (grille 2D)
        
        Plus complexe: contraction exacte est exponentielle
        Utiliser approximations (boundary MPS, etc.)
        """
        return {
            'strategy': 'Boundary contraction avec MPS approximation',
            'complexity': 'O(n^2 * d^4) au lieu de O(d^10)',
            'trade_off': 'Approximation vs exactitude'
        }

# Exemple MPS
specific = SpecificNetworkOptimization()

mps_bonds = [10, 20, 30, 20, 10]  # 4 tenseurs avec ces bond dimensions
mps_order = specific.mps_optimal_order(mps_bonds)

print("\n" + "="*70)
print("Optimisation pour MPS")
print("="*70)
print(f"Ordre optimal: {mps_order['order']}")
print(f"Complexit√©: {mps_order['complexity']}")
print(f"M√©moire: {mps_order['memory']}")
```

---

## Exercices

### Exercice 17.2.1
Trouvez l'ordonnancement optimal pour contracter 5 tenseurs avec shapes donn√©es en minimisant la complexit√© computationnelle.

### Exercice 17.2.2
Impl√©mentez une heuristique gloutonne qui minimise la m√©moire peak et comparez avec minimisation de complexit√©.

### Exercice 17.2.3
Analysez la complexit√© de diff√©rents ordres de contraction pour un r√©seau MPS √† 10 tenseurs.

### Exercice 17.2.4
D√©veloppez une m√©thode d'approximation pour ordonnancement de PEPS qui trouve un compromis temps/m√©moire.

---

## Points Cl√©s √† Retenir

> üìå **L'ordonnancement optimal peut r√©duire complexit√© et m√©moire de plusieurs ordres de grandeur**

> üìå **Recherche exhaustive est possible seulement pour petit nombre de tenseurs (N < 10)**

> üìå **Heuristiques gloutonnes sont rapides mais peuvent √™tre sous-optimales**

> üìå **Programmation dynamique trouve optimal mais co√ªt exponentiel en nombre de tenseurs**

> üìå **Pour r√©seaux sp√©cifiques (MPS, TT), ordres optimaux sont connus**

> üìå **Les approximations sont n√©cessaires pour grands r√©seaux (PEPS, MERA)**

---

*Section pr√©c√©dente : [17.1 Impl√©mentation Efficace des Contractions](./17_01_Contractions.md) | Section suivante : [17.3 Mapping sur Architectures Parall√®les](./17_03_Mapping.md)*

