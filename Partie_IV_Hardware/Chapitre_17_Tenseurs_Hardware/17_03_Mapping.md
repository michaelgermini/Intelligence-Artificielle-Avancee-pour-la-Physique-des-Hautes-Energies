# 17.3 Mapping sur Architectures Parall√®les

---

## Introduction

Le **mapping de r√©seaux de tenseurs sur architectures parall√®les** consiste √† r√©partir les calculs et donn√©es sur plusieurs unit√©s de calcul (CPU cores, GPU streaming multiprocessors, FPGA Processing Elements) pour exploiter le parall√©lisme.

Cette section pr√©sente les strat√©gies de mapping pour diff√©rents types d'architectures parall√®les, incluant le parall√©lisme de donn√©es, de mod√®les, et hybride.

---

## Types de Parall√©lisme

### Classification

```python
class ParallelismTypes:
    """
    Types de parall√©lisme pour r√©seaux de tenseurs
    """
    
    def __init__(self):
        self.parallelism_types = {
            'data_parallelism': {
                'description': 'R√©partir donn√©es sur diff√©rentes unit√©s',
                'example': 'Chaque GPU traite un batch diff√©rent',
                'best_for': 'Batch processing, donn√©es ind√©pendantes',
                'communication': 'Faible (gradients seulement)'
            },
            'model_parallelism': {
                'description': 'R√©partir mod√®le sur diff√©rentes unit√©s',
                'example': 'Chaque GPU contient une partie du r√©seau',
                'best_for': 'Mod√®les trop grands pour un device',
                'communication': '√âlev√©e (activations entre unit√©s)'
            },
            'tensor_parallelism': {
                'description': 'Parall√©liser op√©rations tensorielles',
                'example': 'D√©couper contractions sur plusieurs unit√©s',
                'best_for': 'Contractions grandes',
                'communication': 'Mod√©r√©e (r√©sultats partiels)'
            },
            'pipeline_parallelism': {
                'description': 'Pipeline de calculs s√©quentiels',
                'example': 'Chaque device traite une √©tape du pipeline',
                'best_for': 'S√©quences de calculs',
                'communication': 'Mod√©r√©e (activation forwarding)'
            }
        }
    
    def display_types(self):
        """Affiche les types de parall√©lisme"""
        print("\n" + "="*70)
        print("Types de Parall√©lisme")
        print("="*70)
        
        for ptype, info in self.parallelism_types.items():
            print(f"\n{ptype.replace('_', ' ').title()}:")
            print(f"  Description: {info['description']}")
            print(f"  Example: {info['example']}")
            print(f"  Best for: {info['best_for']}")
            print(f"  Communication: {info['communication']}")

parallelism = ParallelismTypes()
parallelism.display_types()
```

---

## Mapping sur GPU Multi-Cards

### Data Parallelism

```python
import torch
import torch.nn as nn
import torch.distributed as dist

class GPUMultiCardMapping:
    """
    Mapping sur GPU multi-cards
    """
    
    def __init__(self, n_gpus=4):
        """
        Args:
            n_gpus: Nombre de GPUs disponibles
        """
        self.n_gpus = n_gpus
        self.devices = [f'cuda:{i}' for i in range(n_gpus)]
    
    def data_parallel_tensor_network(self, model, batch_size=64):
        """
        Data parallelism: chaque GPU traite un sous-batch
        """
        batch_per_gpu = batch_size // self.n_gpus
        
        def forward_data_parallel(inputs):
            """Forward pass distribu√©"""
            outputs = []
            
            # R√©partir batch sur GPUs
            for i, device in enumerate(self.devices):
                start_idx = i * batch_per_gpu
                end_idx = start_idx + batch_per_gpu
                batch_slice = inputs[start_idx:end_idx].to(device)
                
                # Forward sur ce GPU
                model_device = model.to(device)
                output_slice = model_device(batch_slice)
                outputs.append(output_slice.cpu())
            
            # Combiner r√©sultats
            return torch.cat(outputs, dim=0)
        
        return forward_data_parallel
    
    def model_parallel_tensor_network(self, tensor_layers):
        """
        Model parallelism: r√©partir couches tensorielles sur GPUs
        
        Pour r√©seau de tenseurs: r√©partir tenseurs sur diff√©rents GPUs
        """
        layers_per_gpu = len(tensor_layers) // self.n_gpus
        
        gpu_layers = {}
        for i, device in enumerate(self.devices):
            start_idx = i * layers_per_gpu
            end_idx = start_idx + layers_per_gpu if i < self.n_gpus - 1 else len(tensor_layers)
            gpu_layers[device] = tensor_layers[start_idx:end_idx]
        
        def forward_model_parallel(inputs):
            """Forward avec mod√®le distribu√©"""
            current_input = inputs.to(self.devices[0])
            
            for device in self.devices:
                layers = gpu_layers[device]
                current_input = current_input.to(device)
                
                # Appliquer couches sur ce GPU
                for layer in layers:
                    current_input = layer(current_input)
                
                # Transf√©rer vers prochain GPU si n√©cessaire
                if device != self.devices[-1]:
                    current_input = current_input.to(self.devices[self.devices.index(device) + 1])
            
            return current_input
        
        return forward_model_parallel
    
    def tensor_parallel_contraction(self, tensor_A, tensor_B, n_splits=4):
        """
        Parall√©liser une contraction tensorielle sur plusieurs GPUs
        
        Strat√©gie: d√©couper tenseurs et calculer par morceaux
        """
        # Pour A[i,j,k] * B[j,k,l] ‚Üí C[i,l]
        # D√©couper sur dimension i
        
        if len(tensor_A.shape) == 3 and len(tensor_B.shape) == 3:
            i_dim, j_dim, k_dim = tensor_A.shape
            _, _, l_dim = tensor_B.shape
            
            split_size = i_dim // n_splits
            results = []
            
            for gpu_idx, device in enumerate(self.devices[:n_splits]):
                start_i = gpu_idx * split_size
                end_i = start_i + split_size if gpu_idx < n_splits - 1 else i_dim
                
                # Slice de A
                A_slice = tensor_A[start_i:end_i, :, :].to(device)
                B_device = tensor_B.to(device)
                
                # Contraction sur ce GPU
                C_slice = torch.einsum('ijk,jkl->il', A_slice, B_device)
                results.append(C_slice.cpu())
            
            # Combiner r√©sultats
            C = torch.cat(results, dim=0)
            return C
        else:
            # Fallback
            return torch.einsum('ijk,jkl->il', tensor_A, tensor_B)

# Exemple
if torch.cuda.device_count() >= 2:
    gpu_mapper = GPUMultiCardMapping(n_gpus=min(2, torch.cuda.device_count()))
    print(f"\nMapping sur {gpu_mapper.n_gpus} GPUs")
else:
    print("\nGPUs multiples non disponibles")
```

---

## Mapping sur FPGA Multi-Chip

### Distribution Spatiale

```python
class FPGAMultiChipMapping:
    """
    Mapping sur plusieurs FPGAs
    """
    
    def __init__(self, n_fpgas=4, pe_per_fpga=64):
        """
        Args:
            n_fpgas: Nombre de FPGAs
            pe_per_fpga: PEs par FPGA
        """
        self.n_fpgas = n_fpgas
        self.pe_per_fpga = pe_per_fpga
        self.total_pe = n_fpgas * pe_per_fpga
    
    def spatial_mapping_mps(self, mps_tensors, bond_dimensions):
        """
        Mapping spatial d'un MPS sur plusieurs FPGAs
        
        Strat√©gie: R√©partir tenseurs MPS sur FPGAs diff√©rents
        """
        n_tensors = len(mps_tensors)
        tensors_per_fpga = n_tensors // self.n_fpgas
        
        mapping = {}
        for fpga_id in range(self.n_fpgas):
            start_idx = fpga_id * tensors_per_fpga
            end_idx = start_idx + tensors_per_fpga if fpga_id < self.n_fpgas - 1 else n_tensors
            
            mapping[f'fpga_{fpga_id}'] = {
                'tensor_indices': list(range(start_idx, end_idx)),
                'pe_count': self.pe_per_fpga,
                'bond_dimensions': bond_dimensions[start_idx:end_idx+1]
            }
        
        return mapping
    
    def pipeline_mapping(self, contraction_sequence):
        """
        Mapping pipeline: chaque FPGA traite une √©tape
        
        Avantage: Throughput √©lev√© avec plusieurs √©v√©nements en pipeline
        """
        n_steps = len(contraction_sequence)
        steps_per_fpga = max(1, n_steps // self.n_fpgas)
        
        pipeline = {}
        for fpga_id in range(self.n_fpgas):
            start_step = fpga_id * steps_per_fpga
            end_step = start_step + steps_per_fpga if fpga_id < self.n_fpgas - 1 else n_steps
            
            pipeline[f'fpga_{fpga_id}'] = {
                'contraction_steps': contraction_sequence[start_step:end_step],
                'pipeline_stage': fpga_id,
                'pe_count': self.pe_per_fpga
            }
        
        # Estimer latence pipeline
        latency_per_stage = 100  # ns (exemple)
        pipeline_latency = latency_per_stage * len(pipeline)
        pipeline_throughput = 1.0 / (latency_per_stage * 1e-9)  # events/sec
        
        return {
            'pipeline': pipeline,
            'latency_ns': pipeline_latency,
            'throughput_events_per_sec': pipeline_throughput
        }
    
    def estimate_inter_fpga_communication(self, mapping):
        """
        Estime la communication n√©cessaire entre FPGAs
        """
        communication = {
            'data_transfer_size_bytes': 0,
            'bandwidth_required_gbps': 0,
            'latency_overhead_ns': 0
        }
        
        # Simplifi√©: estime selon mapping
        # En pratique, d√©pend de la structure du r√©seau
        
        return communication

fpga_mapper = FPGAMultiChipMapping(n_fpgas=4, pe_per_fpga=64)

# Exemple MPS
mps_tensors = list(range(10))  # 10 tenseurs
bond_dims = [10] * 11

spatial_map = fpga_mapper.spatial_mapping_mps(mps_tensors, bond_dims)

print("\n" + "="*70)
print("Mapping Spatial MPS sur FPGAs")
print("="*70)
for fpga, config in spatial_map.items():
    print(f"\n{fpga}:")
    print(f"  Tenseurs: {config['tensor_indices']}")
    print(f"  PEs: {config['pe_count']}")
```

---

## Mapping Hybride CPU-GPU

### Partitionnement Adaptatif

```python
class HybridCPUGPUMapping:
    """
    Mapping hybride sur CPU et GPU
    """
    
    def __init__(self):
        self.has_gpu = torch.cuda.is_available()
    
    def adaptive_mapping(self, contraction_sequence, tensor_sizes):
        """
        Mapping adaptatif: assigne √† CPU ou GPU selon taille/complexit√©
        """
        mapping = []
        
        for i, (contraction, size_A, size_B) in enumerate(zip(contraction_sequence, 
                                                               tensor_sizes[:-1], 
                                                               tensor_sizes[1:])):
            # Heuristique: GPU pour grandes op√©rations, CPU pour petites
            total_size = size_A * size_B
            
            if self.has_gpu and total_size > 1e6:  # Seuil
                device = 'gpu'
            else:
                device = 'cpu'
            
            mapping.append({
                'contraction': contraction,
                'device': device,
                'size': total_size
            })
        
        return mapping
    
    def load_balancing_mapping(self, contractions, n_cpu_cores=8, n_gpus=1):
        """
        Mapping avec √©quilibrage de charge
        
        R√©partit contractions pour minimiser temps total
        """
        # Estimer temps pour chaque contraction
        contraction_times = []
        for contraction, size_A, size_B in zip(contractions, 
                                               tensor_sizes[:-1], 
                                               tensor_sizes[1:]):
            # Estimation simplifi√©e
            ops = size_A * size_B
            time_cpu = ops / (n_cpu_cores * 1e9)  # Gops/sec par core
            time_gpu = ops / (n_gpus * 1e12) if self.has_gpu else float('inf')  # Tops/sec
            
            contraction_times.append({
                'contraction': contraction,
                'time_cpu': time_cpu,
                'time_gpu': time_gpu,
                'best_device': 'gpu' if time_gpu < time_cpu else 'cpu'
            })
        
        # Assigner avec √©quilibrage
        cpu_load = 0
        gpu_load = 0
        mapping = []
        
        for ct in sorted(contraction_times, key=lambda x: max(x['time_cpu'], x['time_gpu']), 
                        reverse=True):
            if ct['best_device'] == 'gpu' and gpu_load <= cpu_load:
                mapping.append({'contraction': ct['contraction'], 'device': 'gpu'})
                gpu_load += ct['time_gpu']
            else:
                mapping.append({'contraction': ct['contraction'], 'device': 'cpu'})
                cpu_load += ct['time_cpu']
        
        return {
            'mapping': mapping,
            'cpu_load': cpu_load,
            'gpu_load': gpu_load,
            'total_time': max(cpu_load, gpu_load)
        }

hybrid_mapper = HybridCPUGPUMapping()
```

---

## Communication et Synchronisation

### Gestion des Donn√©es Distribu√©es

```python
class CommunicationOptimization:
    """
    Optimisation de la communication dans mapping distribu√©
    """
    
    def reduce_communication_overhead(self, mapping):
        """
        R√©duit overhead de communication
        
        Strat√©gies:
        - Fusionner communications
        - Pipeline communication/computation
        - Compression des donn√©es
        """
        strategies = {
            'communication_fusion': {
                'description': 'Fusionner plusieurs transfers en un',
                'benefit': 'R√©duit latence et overhead'
            },
            'pipeline_comm_compute': {
                'description': 'Overlap communication et computation',
                'benefit': 'Masque latence communication'
            },
            'data_compression': {
                'description': 'Compresser donn√©es transf√©r√©es',
                'benefit': 'R√©duit bandwidth n√©cessaire'
            },
            'local_accumulation': {
                'description': 'Accumuler localement avant communication',
                'benefit': 'R√©duit nombre de communications'
            }
        }
        
        return strategies
    
    def allreduce_optimization(self, n_devices):
        """
        Optimise AllReduce (somme sur tous devices)
        
        Important pour data parallelism et accumulation de gradients
        """
        # Ring AllReduce: O(n) communication au lieu de O(n¬≤)
        ring_steps = n_devices - 1
        
        return {
            'algorithm': 'Ring AllReduce',
            'communication_steps': ring_steps,
            'bandwidth_efficient': True
        }

comm_opt = CommunicationOptimization()
strategies = comm_opt.reduce_communication_overhead({})
print("\nStrat√©gies d'optimisation communication:")
for strategy, info in strategies.items():
    print(f"  {strategy}: {info['description']}")
```

---

## Cas d'Usage: R√©seau MPS Distribu√©

### Exemple Complet

```python
class DistributedMPSExample:
    """
    Exemple complet de mapping distribu√© d'un MPS
    """
    
    def map_mps_to_hardware(self, n_tensors=20, bond_dim=32, 
                           n_fpgas=4, batch_size=100):
        """
        Mapping complet d'un MPS sur hardware distribu√©
        """
        # 1. D√©composer MPS
        mps_structure = {
            'n_tensors': n_tensors,
            'bond_dimension': bond_dim,
            'physical_dim': 2  # Exemple: spin-1/2
        }
        
        # 2. Ordonnancement optimal (s√©quentiel pour MPS)
        contraction_order = [(i, i+1) for i in range(n_tensors - 1)]
        
        # 3. Mapping spatial: r√©partir tenseurs sur FPGAs
        fpga_mapper = FPGAMultiChipMapping(n_fpgas=n_fpgas)
        spatial_mapping = fpga_mapper.spatial_mapping_mps(
            list(range(n_tensors)), [bond_dim] * (n_tensors + 1)
        )
        
        # 4. Estimer performance
        contractions_per_fpga = n_tensors // n_fpgas
        latency_per_contraction_ns = 100  # Exemple
        total_latency_ns = contractions_per_fpga * latency_per_contraction_ns
        
        # 5. Communication inter-FPGA
        comm_overhead_ns = (n_fpgas - 1) * 50  # Exemple
        
        total_latency = total_latency_ns + comm_overhead_ns
        
        return {
            'mps_structure': mps_structure,
            'contraction_order': contraction_order,
            'spatial_mapping': spatial_mapping,
            'estimated_latency_ns': total_latency,
            'estimated_throughput': batch_size / (total_latency * 1e-9)
        }

# Exemple
distributed_example = DistributedMPSExample()
result = distributed_example.map_mps_to_hardware()

print("\n" + "="*70)
print("Exemple: MPS Distribu√©")
print("="*70)
print(f"Latence estim√©e: {result['estimated_latency_ns']/1000:.2f} Œºs")
print(f"Throughput: {result['estimated_throughput']:.2e} events/sec")
```

---

## Exercices

### Exercice 17.3.1
Impl√©mentez un mapping data-parallel pour un r√©seau de tenseurs sur 4 GPUs et mesurez le speedup.

### Exercice 17.3.2
Concevez un mapping pipeline d'un MPS sur 4 FPGAs et estimez le throughput avec events en pipeline.

### Exercice 17.3.3
Cr√©ez un syst√®me de mapping adaptatif qui assigne automatiquement contractions √† CPU ou GPU selon leur taille.

### Exercice 17.3.4
Optimisez la communication dans un mapping distribu√© en utilisant Ring AllReduce et comparez avec communication naive.

---

## Points Cl√©s √† Retenir

> üìå **Data parallelism est simple mais n√©cessite batch processing**

> üìå **Model/tensor parallelism permet de traiter mod√®les plus grands mais avec plus de communication**

> üìå **Pipeline parallelism am√©liore throughput pour s√©quences de calculs**

> üìå **Mapping hybride CPU-GPU peut optimiser utilisation ressources h√©t√©rog√®nes**

> üìå **Communication est souvent le bottleneck dans mapping distribu√©**

> üìå **Optimisations (Ring AllReduce, fusion, pipelining) sont essentielles**

---

*Section pr√©c√©dente : [17.2 Ordonnancement Optimal](./17_02_Ordonnancement.md) | Section suivante : [17.4 Quantification Hardware-Aware](./17_04_Quantification.md)*

