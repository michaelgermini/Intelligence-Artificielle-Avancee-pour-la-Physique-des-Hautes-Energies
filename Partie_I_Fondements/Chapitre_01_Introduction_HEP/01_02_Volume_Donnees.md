# 1.2 Volume et VÃ©locitÃ© des DonnÃ©es en Physique des Particules

---

## Introduction

La physique des hautes Ã©nergies est entrÃ©e dans l'Ã¨re du **Big Data** bien avant que ce terme ne devienne populaire. Les expÃ©riences du LHC gÃ©nÃ¨rent des volumes de donnÃ©es qui dÃ©fient l'imagination et nÃ©cessitent des infrastructures de calcul distribuÃ©es Ã  l'Ã©chelle mondiale.

---

## Les Quatre V du Big Data en HEP

### Volume

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HiÃ©rarchie des DonnÃ©es LHC                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  DonnÃ©es brutes (avant trigger)     â”‚  ~60 PB/s               â”‚
â”‚           â†“ Trigger L1              â”‚                         â”‚
â”‚  AprÃ¨s L1 (~100 kHz)                â”‚  ~150 GB/s              â”‚
â”‚           â†“ HLT                     â”‚                         â”‚
â”‚  DonnÃ©es enregistrÃ©es               â”‚  ~1-2 GB/s              â”‚
â”‚           â†“ Reconstruction          â”‚                         â”‚
â”‚  DonnÃ©es analysables                â”‚  ~100 PB/an             â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Statistiques de Stockage (2023)

| ExpÃ©rience | DonnÃ©es brutes/an | DonnÃ©es reconstruites/an |
|------------|-------------------|-------------------------|
| ATLAS | ~50 PB | ~100 PB |
| CMS | ~50 PB | ~100 PB |
| ALICE | ~30 PB | ~50 PB |
| LHCb | ~20 PB | ~40 PB |

### VÃ©locitÃ©

La vÃ©locitÃ© des donnÃ©es est dictÃ©e par la physique du LHC :

```python
# Calcul du dÃ©bit de donnÃ©es
class LHCDataRate:
    BUNCH_CROSSING_FREQ = 40e6  # 40 MHz
    AVG_PILEUP = 50  # collisions par croisement
    RAW_EVENT_SIZE = 1.5e6  # bytes
    
    @classmethod
    def raw_data_rate(cls):
        """DÃ©bit brut thÃ©orique en bytes/s"""
        return cls.BUNCH_CROSSING_FREQ * cls.RAW_EVENT_SIZE
    
    @classmethod
    def collisions_per_second(cls):
        """Nombre de collisions par seconde"""
        return cls.BUNCH_CROSSING_FREQ * cls.AVG_PILEUP

# RÃ©sultats
print(f"DÃ©bit brut: {LHCDataRate.raw_data_rate() / 1e15:.1f} PB/s")
print(f"Collisions/s: {LHCDataRate.collisions_per_second():.2e}")
```

Output:
```
DÃ©bit brut: 60.0 PB/s
Collisions/s: 2.00e+09
```

### VariÃ©tÃ©

Les donnÃ©es HEP prÃ©sentent une grande diversitÃ© :

1. **DonnÃ©es de dÃ©tecteur** : Signaux Ã©lectroniques bruts
2. **DonnÃ©es reconstruites** : Traces, clusters, jets
3. **DonnÃ©es simulÃ©es** : Monte Carlo
4. **MÃ©tadonnÃ©es** : Conditions de prise de donnÃ©es
5. **DonnÃ©es dÃ©rivÃ©es** : Formats d'analyse (AOD, NANO)

### VÃ©racitÃ©

La qualitÃ© des donnÃ©es est critique :

- **Calibration** : Correction des rÃ©ponses des dÃ©tecteurs
- **Alignement** : Positionnement prÃ©cis des sous-dÃ©tecteurs
- **Data Quality** : Validation de chaque run de donnÃ©es

---

## Le Worldwide LHC Computing Grid (WLCG)

### Architecture HiÃ©rarchique

Le WLCG est organisÃ© en niveaux (Tiers) :

```
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Tier-0    â”‚
                        â”‚    CERN     â”‚
                        â”‚  ~200 PB    â”‚
                        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                   â”‚                   â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
     â”‚  Tier-1   â”‚       â”‚  Tier-1   â”‚       â”‚  Tier-1   â”‚
     â”‚   (13)    â”‚       â”‚   (13)    â”‚       â”‚   (13)    â”‚
     â”‚  ~50 PB   â”‚       â”‚  ~50 PB   â”‚       â”‚  ~50 PB   â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚                   â”‚                   â”‚
     â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
     â”‚  Tier-2   â”‚       â”‚  Tier-2   â”‚       â”‚  Tier-2   â”‚
     â”‚  (~160)   â”‚       â”‚  (~160)   â”‚       â”‚  (~160)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RÃ´les des DiffÃ©rents Tiers

| Tier | Localisation | RÃ´le Principal | CapacitÃ© Typique |
|------|--------------|----------------|------------------|
| 0 | CERN | Reconstruction primaire, archivage | ~200 PB stockage |
| 1 | 13 centres nationaux | Reprocessing, stockage permanent | ~50 PB chacun |
| 2 | ~160 centres | Simulation, analyse utilisateur | ~5-20 PB chacun |
| 3 | UniversitÃ©s | Analyse locale | Variable |

### CapacitÃ© Totale du WLCG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Ressources WLCG (2023)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Stockage total : > 1 Exabyte                            â”‚
â”‚  â€¢ Puissance de calcul : > 1 million de cÅ“urs CPU          â”‚
â”‚  â€¢ Sites : > 170 dans 42 pays                              â”‚
â”‚  â€¢ Transfert de donnÃ©es : ~50 GB/s en continu              â”‚
â”‚  â€¢ Jobs par jour : > 2 millions                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Formats de DonnÃ©es

### HiÃ©rarchie des Formats

```
RAW (DonnÃ©es brutes du dÃ©tecteur)
    â”‚
    â–¼ Reconstruction
ESD/AOD (Event Summary Data / Analysis Object Data)
    â”‚
    â–¼ DÃ©rivation
DAOD (Derived AOD - formats spÃ©cialisÃ©s)
    â”‚
    â–¼ RÃ©duction finale
NANO/MINI (Formats compacts pour analyse)
```

### Exemple de Structure de DonnÃ©es

```python
import numpy as np
from dataclasses import dataclass
from typing import List

@dataclass
class Particle:
    """ReprÃ©sentation d'une particule reconstruite"""
    pt: float      # Impulsion transverse (GeV)
    eta: float     # Pseudo-rapiditÃ©
    phi: float     # Angle azimuthal
    mass: float    # Masse (GeV)
    pdg_id: int    # Identifiant de particule
    charge: int    # Charge Ã©lectrique

@dataclass
class Event:
    """Structure d'un Ã©vÃ©nement de collision"""
    run_number: int
    event_number: int
    lumi_block: int
    
    # Collections de particules
    electrons: List[Particle]
    muons: List[Particle]
    photons: List[Particle]
    jets: List[Particle]
    
    # Variables globales
    met: float           # Ã‰nergie transverse manquante
    met_phi: float       # Direction du MET
    n_vertices: int      # Nombre de vertex primaires
    
    def total_particles(self) -> int:
        return (len(self.electrons) + len(self.muons) + 
                len(self.photons) + len(self.jets))

# Taille typique d'un Ã©vÃ©nement en format NANO
# ~1-5 KB par Ã©vÃ©nement (vs ~1.5 MB en RAW)
```

### Compression et Stockage

```python
# Comparaison des tailles de fichiers
data_formats = {
    'RAW': {'size_per_event_kb': 1500, 'compression': 1.0},
    'ESD': {'size_per_event_kb': 500, 'compression': 3.0},
    'AOD': {'size_per_event_kb': 100, 'compression': 15.0},
    'DAOD': {'size_per_event_kb': 20, 'compression': 75.0},
    'NANO': {'size_per_event_kb': 2, 'compression': 750.0},
}

print("Format | Taille/evt | Facteur de compression")
print("-" * 50)
for fmt, info in data_formats.items():
    print(f"{fmt:6} | {info['size_per_event_kb']:6} KB | {info['compression']:6.0f}x")
```

---

## DÃ©fis de Gestion des DonnÃ©es

### 1. Stockage Ã  Long Terme

Les donnÃ©es du LHC doivent Ãªtre prÃ©servÃ©es pour des dÃ©cennies :

- **DurÃ©e de vie** : Les donnÃ©es du Run 1 (2010-2012) sont toujours analysÃ©es
- **Formats Ã©volutifs** : Migration vers de nouveaux formats
- **AccessibilitÃ©** : AccÃ¨s rapide pour la rÃ©analyse

### 2. Transfert de DonnÃ©es

```python
# Calcul du temps de transfert
def transfer_time(data_size_pb, bandwidth_gbps):
    """
    Calcule le temps de transfert en heures
    
    Args:
        data_size_pb: Taille en pÃ©taoctets
        bandwidth_gbps: Bande passante en Gb/s
    """
    data_bits = data_size_pb * 1e15 * 8  # Conversion en bits
    bandwidth_bps = bandwidth_gbps * 1e9
    time_seconds = data_bits / bandwidth_bps
    return time_seconds / 3600  # Conversion en heures

# Exemple : TransfÃ©rer 1 PB Ã  100 Gb/s
time_hours = transfer_time(1, 100)
print(f"Temps pour transfÃ©rer 1 PB Ã  100 Gb/s: {time_hours:.1f} heures")
# Output: Temps pour transfÃ©rer 1 PB Ã  100 Gb/s: 22.2 heures
```

### 3. Traitement DistribuÃ©

Les analyses nÃ©cessitent un traitement massivement parallÃ¨le :

```python
# Exemple simplifiÃ© de job distribuÃ©
class DistributedAnalysis:
    def __init__(self, n_events, events_per_job=10000):
        self.n_events = n_events
        self.events_per_job = events_per_job
        self.n_jobs = n_events // events_per_job
    
    def estimate_walltime(self, time_per_event_ms, n_cores):
        """Estime le temps total d'analyse"""
        total_time_ms = self.n_events * time_per_event_ms
        walltime_hours = total_time_ms / (n_cores * 1000 * 3600)
        return walltime_hours

# Analyse de 1 milliard d'Ã©vÃ©nements
analysis = DistributedAnalysis(n_events=1e9)
print(f"Nombre de jobs: {analysis.n_jobs:,}")

# Avec 10000 cÅ“urs et 10ms par Ã©vÃ©nement
walltime = analysis.estimate_walltime(time_per_event_ms=10, n_cores=10000)
print(f"Temps estimÃ©: {walltime:.1f} heures")
```

---

## Ã‰volution Future : HL-LHC

Le **High-Luminosity LHC** (prÃ©vu pour 2029) multipliera les dÃ©fis :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Comparaison LHC vs HL-LHC                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                        â”‚    LHC (Run 3)    â”‚     HL-LHC        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  LuminositÃ© inst.      â”‚    2Ã—10Â³â´         â”‚    5-7.5Ã—10Â³â´     â”‚
â”‚  Pile-up moyen         â”‚    ~50            â”‚    ~140-200       â”‚
â”‚  DonnÃ©es/an            â”‚    ~100 PB        â”‚    ~500 PB        â”‚
â”‚  Stockage total prÃ©vu  â”‚    ~1 EB          â”‚    ~5 EB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implications pour l'IA

L'augmentation du pile-up nÃ©cessite des algorithmes plus sophistiquÃ©s :

1. **Reconstruction plus complexe** : Plus de particules Ã  dÃ©mÃªler
2. **Meilleure discrimination** : SÃ©parer signal du bruit de fond
3. **EfficacitÃ© accrue** : Traiter plus de donnÃ©es avec les mÃªmes ressources
4. **Compression agressive** : RÃ©duire les besoins de stockage

---

## Exercices

### Exercice 1.2.1
Le WLCG transfÃ¨re en moyenne 50 GB/s de donnÃ©es. Combien de temps faudrait-il pour transfÃ©rer l'ensemble des donnÃ©es du Run 2 (~300 PB) Ã  cette vitesse ?

### Exercice 1.2.2
Si le HL-LHC gÃ©nÃ¨re 5 fois plus de donnÃ©es que le LHC actuel, mais que le budget de stockage n'augmente que de 50%, quel facteur de compression supplÃ©mentaire faut-il atteindre ?

### Exercice 1.2.3
Un format NANO contient en moyenne 2 KB par Ã©vÃ©nement. Combien d'Ã©vÃ©nements peut-on stocker sur un disque de 10 TB ?

---

## Points ClÃ©s Ã  Retenir

> ðŸ“Œ **Le LHC gÃ©nÃ¨re ~100 PB de donnÃ©es par an, stockÃ©es sur le WLCG**

> ðŸ“Œ **Le WLCG comprend plus de 170 sites dans 42 pays**

> ðŸ“Œ **Les donnÃ©es passent par plusieurs formats, de RAW (~1.5 MB) Ã  NANO (~2 KB)**

> ðŸ“Œ **Le HL-LHC multipliera les dÃ©fis par 5 Ã  partir de 2029**

---

## RÃ©fÃ©rences

1. Bird, I. et al. "Update of the Computing Models of the WLCG and the LHC Experiments." CERN-LHCC-2014-014
2. ATLAS Collaboration. "ATLAS Computing and Data Handling." ATL-SOFT-PUB-2022-001
3. Albrecht, J. et al. "A Roadmap for HEP Software and Computing R&D for the 2020s." Comput Softw Big Sci 3, 7 (2019)

---

*Section suivante : [1.3 DÃ©fis du Traitement en Temps RÃ©el](./01_03_Temps_Reel.md)*

