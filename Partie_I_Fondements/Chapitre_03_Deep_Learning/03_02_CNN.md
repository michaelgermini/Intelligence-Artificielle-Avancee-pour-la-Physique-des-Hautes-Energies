# 3.2 R√©seaux Convolutionnels (CNN)

---

## Introduction

Les **R√©seaux de Neurones Convolutionnels** (CNN) sont sp√©cialement con√ßus pour traiter des donn√©es structur√©es en grille (images, s√©ries temporelles). Ils exploitent trois id√©es cl√©s : les connexions locales, le partage de poids, et l'invariance par translation.

---

## Op√©ration de Convolution

### D√©finition Math√©matique

Pour une image 2D $\mathbf{I}$ et un noyau $\mathbf{K}$ :

$$(I * K)_{i,j} = \sum_m \sum_n I_{i+m, j+n} \cdot K_{m,n}$$

```python
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

def conv2d_manual(image, kernel, stride=1, padding=0):
    """
    Impl√©mentation manuelle de la convolution 2D
    """
    # Padding
    if padding > 0:
        image = np.pad(image, ((padding, padding), (padding, padding)), mode='constant')
    
    H, W = image.shape
    kH, kW = kernel.shape
    
    # Dimensions de sortie
    out_H = (H - kH) // stride + 1
    out_W = (W - kW) // stride + 1
    
    output = np.zeros((out_H, out_W))
    
    for i in range(out_H):
        for j in range(out_W):
            # R√©gion de l'image
            region = image[i*stride:i*stride+kH, j*stride:j*stride+kW]
            # Produit √©l√©ment par √©l√©ment et somme
            output[i, j] = np.sum(region * kernel)
    
    return output

# Exemple avec un filtre de d√©tection de bords
image = np.random.randn(28, 28)

# Filtre Sobel (d√©tection de bords verticaux)
sobel_x = np.array([
    [-1, 0, 1],
    [-2, 0, 2],
    [-1, 0, 1]
])

edges = conv2d_manual(image, sobel_x, padding=1)
print(f"Image: {image.shape} ‚Üí Sortie: {edges.shape}")
```

### Convolution avec Canaux Multiples

```python
def conv2d_multichannel(input_tensor, kernels, bias=None, stride=1, padding=0):
    """
    Convolution avec entr√©e multi-canaux et filtres multiples
    
    input_tensor: (C_in, H, W)
    kernels: (C_out, C_in, kH, kW)
    output: (C_out, H_out, W_out)
    """
    C_in, H, W = input_tensor.shape
    C_out, _, kH, kW = kernels.shape
    
    # Padding
    if padding > 0:
        input_tensor = np.pad(
            input_tensor, 
            ((0, 0), (padding, padding), (padding, padding)),
            mode='constant'
        )
    
    _, H_pad, W_pad = input_tensor.shape
    
    # Dimensions de sortie
    H_out = (H_pad - kH) // stride + 1
    W_out = (W_pad - kW) // stride + 1
    
    output = np.zeros((C_out, H_out, W_out))
    
    for c_out in range(C_out):
        for i in range(H_out):
            for j in range(W_out):
                # Somme sur tous les canaux d'entr√©e
                for c_in in range(C_in):
                    region = input_tensor[c_in, 
                                         i*stride:i*stride+kH, 
                                         j*stride:j*stride+kW]
                    output[c_out, i, j] += np.sum(region * kernels[c_out, c_in])
                
                if bias is not None:
                    output[c_out, i, j] += bias[c_out]
    
    return output

# Exemple
input_3ch = np.random.randn(3, 32, 32)  # Image RGB 32x32
filters = np.random.randn(16, 3, 3, 3)   # 16 filtres 3x3

output = conv2d_multichannel(input_3ch, filters, padding=1)
print(f"Input: {input_3ch.shape} ‚Üí Output: {output.shape}")
```

---

## Couches Fondamentales

### Couche de Convolution

```python
class ConvBlock(nn.Module):
    """
    Bloc de convolution standard: Conv ‚Üí BatchNorm ‚Üí Activation
    """
    
    def __init__(self, in_channels, out_channels, kernel_size=3, 
                 stride=1, padding=1, activation='relu'):
        super().__init__()
        
        self.conv = nn.Conv2d(
            in_channels, out_channels, kernel_size,
            stride=stride, padding=padding, bias=False
        )
        self.bn = nn.BatchNorm2d(out_channels)
        
        self.activation = {
            'relu': nn.ReLU(inplace=True),
            'leaky_relu': nn.LeakyReLU(0.1, inplace=True),
            'gelu': nn.GELU()
        }.get(activation, nn.ReLU(inplace=True))
        
    def forward(self, x):
        return self.activation(self.bn(self.conv(x)))
    
    def count_parameters(self):
        return sum(p.numel() for p in self.parameters())
    
    def count_flops(self, input_shape):
        """Calcule les FLOPs pour cette couche"""
        B, C_in, H, W = input_shape
        C_out = self.conv.out_channels
        K = self.conv.kernel_size[0]
        
        # FLOPs convolution: 2 * K¬≤ * C_in * C_out * H_out * W_out
        H_out = (H + 2*self.conv.padding[0] - K) // self.conv.stride[0] + 1
        W_out = (W + 2*self.conv.padding[1] - K) // self.conv.stride[1] + 1
        
        flops = 2 * K * K * C_in * C_out * H_out * W_out * B
        
        return flops

# Analyse
block = ConvBlock(64, 128, kernel_size=3)
print(f"Param√®tres: {block.count_parameters():,}")
print(f"FLOPs (input 64x32x32): {block.count_flops((1, 64, 32, 32)):,}")
```

### Pooling

```python
class PoolingAnalysis:
    """
    Analyse des diff√©rentes op√©rations de pooling
    """
    
    @staticmethod
    def max_pool(x, kernel_size=2, stride=2):
        """Max pooling: garde la valeur maximale"""
        return F.max_pool2d(x, kernel_size, stride)
    
    @staticmethod
    def avg_pool(x, kernel_size=2, stride=2):
        """Average pooling: moyenne des valeurs"""
        return F.avg_pool2d(x, kernel_size, stride)
    
    @staticmethod
    def global_avg_pool(x):
        """Global average pooling: une valeur par canal"""
        return F.adaptive_avg_pool2d(x, 1)
    
    @staticmethod
    def compare_pooling(x):
        """Compare les diff√©rentes m√©thodes"""
        print(f"Input shape: {x.shape}")
        
        max_out = PoolingAnalysis.max_pool(x)
        print(f"Max pool 2x2: {max_out.shape}")
        
        avg_out = PoolingAnalysis.avg_pool(x)
        print(f"Avg pool 2x2: {avg_out.shape}")
        
        global_out = PoolingAnalysis.global_avg_pool(x)
        print(f"Global avg pool: {global_out.shape}")

# D√©monstration
x = torch.randn(1, 64, 32, 32)
PoolingAnalysis.compare_pooling(x)
```

---

## Architectures Classiques

### VGG-style

```python
class VGGBlock(nn.Module):
    """
    Bloc style VGG: convolutions r√©p√©t√©es puis pooling
    """
    
    def __init__(self, in_channels, out_channels, n_convs=2):
        super().__init__()
        
        layers = []
        for i in range(n_convs):
            layers.append(nn.Conv2d(
                in_channels if i == 0 else out_channels,
                out_channels, 3, padding=1
            ))
            layers.append(nn.BatchNorm2d(out_channels))
            layers.append(nn.ReLU(inplace=True))
        
        layers.append(nn.MaxPool2d(2, 2))
        
        self.block = nn.Sequential(*layers)
        
    def forward(self, x):
        return self.block(x)


class VGGNet(nn.Module):
    """
    Architecture VGG simplifi√©e
    """
    
    def __init__(self, n_classes=10):
        super().__init__()
        
        self.features = nn.Sequential(
            VGGBlock(3, 64, n_convs=2),      # 32 ‚Üí 16
            VGGBlock(64, 128, n_convs=2),    # 16 ‚Üí 8
            VGGBlock(128, 256, n_convs=3),   # 8 ‚Üí 4
            VGGBlock(256, 512, n_convs=3),   # 4 ‚Üí 2
        )
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(512 * 2 * 2, 512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(512, n_classes)
        )
        
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

vgg = VGGNet(n_classes=10)
print(f"VGG params: {sum(p.numel() for p in vgg.parameters()):,}")
```

### ResNet

```python
class ResidualBlock(nn.Module):
    """
    Bloc r√©siduel avec shortcut connection
    """
    
    def __init__(self, in_channels, out_channels, stride=1):
        super().__init__()
        
        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 
                               stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        
        self.conv2 = nn.Conv2d(out_channels, out_channels, 3,
                               padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)
        
        # Shortcut si changement de dimensions
        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )
        
    def forward(self, x):
        identity = self.shortcut(x)
        
        out = F.relu(self.bn1(self.conv1(x)))
        out = self.bn2(self.conv2(out))
        
        out += identity  # Skip connection
        out = F.relu(out)
        
        return out


class ResNet(nn.Module):
    """
    ResNet simplifi√©
    """
    
    def __init__(self, block_counts=[2, 2, 2, 2], n_classes=10):
        super().__init__()
        
        self.in_channels = 64
        
        self.conv1 = nn.Conv2d(3, 64, 7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)
        
        self.layer1 = self._make_layer(64, block_counts[0], stride=1)
        self.layer2 = self._make_layer(128, block_counts[1], stride=2)
        self.layer3 = self._make_layer(256, block_counts[2], stride=2)
        self.layer4 = self._make_layer(512, block_counts[3], stride=2)
        
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))
        self.fc = nn.Linear(512, n_classes)
        
    def _make_layer(self, out_channels, n_blocks, stride):
        layers = []
        layers.append(ResidualBlock(self.in_channels, out_channels, stride))
        self.in_channels = out_channels
        
        for _ in range(1, n_blocks):
            layers.append(ResidualBlock(out_channels, out_channels))
        
        return nn.Sequential(*layers)
    
    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.maxpool(x)
        
        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.fc(x)
        
        return x

resnet = ResNet(n_classes=10)
print(f"ResNet params: {sum(p.numel() for p in resnet.parameters()):,}")
```

---

## Applications en Physique des Particules

### Classification d'Images de Calorim√®tres

```python
class CalorimeterCNN(nn.Module):
    """
    CNN pour classifier les images de calorim√®tres
    
    Entr√©e: Image 3D du calorim√®tre (Œ∑ √ó œÜ √ó couches)
    Sortie: Classification (√©lectron, photon, jet, etc.)
    """
    
    def __init__(self, input_channels=3, n_classes=4):
        super().__init__()
        
        # Couches convolutionnelles
        self.features = nn.Sequential(
            # Bloc 1
            nn.Conv2d(input_channels, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.Conv2d(32, 32, 3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # Bloc 2
            nn.Conv2d(32, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, 3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, 2),
            
            # Bloc 3
            nn.Conv2d(64, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.AdaptiveAvgPool2d((4, 4))
        )
        
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(128 * 4 * 4, 256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(256, n_classes)
        )
        
    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x
    
    def get_feature_maps(self, x):
        """Retourne les feature maps interm√©diaires"""
        features = []
        for layer in self.features:
            x = layer(x)
            if isinstance(layer, nn.Conv2d):
                features.append(x.clone())
        return features

# Classes pour la physique
particle_classes = ['electron', 'photon', 'pi0', 'jet']

calo_cnn = CalorimeterCNN(input_channels=3, n_classes=len(particle_classes))
print(f"CalorimeterCNN params: {sum(p.numel() for p in calo_cnn.parameters()):,}")

# Test
x = torch.randn(1, 3, 32, 32)  # Image calorim√®tre 32x32 avec 3 couches
output = calo_cnn(x)
print(f"Output shape: {output.shape}")
```

### Jet Tagging avec Images de Jets

```python
class JetImageCNN(nn.Module):
    """
    CNN pour le tagging de jets √† partir d'images
    
    L'image du jet est construite en projetant les constituants
    sur un plan (Œ∑, œÜ) centr√© sur l'axe du jet
    """
    
    def __init__(self, image_size=40, n_classes=5):
        super().__init__()
        
        # Architecture inspir√©e de ResNet mais plus l√©g√®re
        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)
        self.bn1 = nn.BatchNorm2d(32)
        
        self.res_blocks = nn.Sequential(
            self._make_res_block(32, 64, stride=2),
            self._make_res_block(64, 64),
            self._make_res_block(64, 128, stride=2),
            self._make_res_block(128, 128),
        )
        
        self.global_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Linear(128, n_classes)
        
    def _make_res_block(self, in_ch, out_ch, stride=1):
        return ResidualBlock(in_ch, out_ch, stride)
    
    def forward(self, x):
        x = F.relu(self.bn1(self.conv1(x)))
        x = self.res_blocks(x)
        x = self.global_pool(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# Classes de jets
jet_classes = ['light_quark', 'gluon', 'charm', 'bottom', 'top']

jet_cnn = JetImageCNN(n_classes=len(jet_classes))
print(f"JetImageCNN params: {sum(p.numel() for p in jet_cnn.parameters()):,}")
```

---

## Opportunit√©s de Compression

### Analyse de Redondance dans les Filtres

```python
def analyze_filter_redundancy(conv_layer):
    """
    Analyse la redondance dans les filtres d'une couche conv
    """
    weights = conv_layer.weight.data.numpy()
    C_out, C_in, kH, kW = weights.shape
    
    # Reshape: chaque filtre devient un vecteur
    filters_flat = weights.reshape(C_out, -1)
    
    # SVD pour analyser le rang effectif
    U, S, Vt = np.linalg.svd(filters_flat, full_matrices=False)
    
    # Rang effectif (99% √©nergie)
    cumsum = np.cumsum(S**2) / np.sum(S**2)
    effective_rank = np.searchsorted(cumsum, 0.99) + 1
    
    # Similarit√© entre filtres (cosine similarity)
    norms = np.linalg.norm(filters_flat, axis=1, keepdims=True)
    normalized = filters_flat / (norms + 1e-10)
    similarity_matrix = normalized @ normalized.T
    
    # Filtres tr√®s similaires
    similar_pairs = np.sum(np.abs(similarity_matrix) > 0.9) - C_out  # Exclut diagonale
    similar_pairs //= 2  # Chaque paire compt√©e 2 fois
    
    return {
        'n_filters': C_out,
        'filter_size': C_in * kH * kW,
        'full_rank': min(C_out, C_in * kH * kW),
        'effective_rank': effective_rank,
        'rank_ratio': effective_rank / min(C_out, C_in * kH * kW),
        'similar_filter_pairs': similar_pairs,
        'singular_values': S[:10]
    }

# Analyse d'un mod√®le
model = CalorimeterCNN()
print("Analyse de redondance des filtres:")
for name, module in model.named_modules():
    if isinstance(module, nn.Conv2d):
        analysis = analyze_filter_redundancy(module)
        print(f"\n{name}:")
        print(f"  Filtres: {analysis['n_filters']}")
        print(f"  Rang effectif: {analysis['effective_rank']} / {analysis['full_rank']}")
        print(f"  Paires similaires: {analysis['similar_filter_pairs']}")
```

### Techniques de Compression pour CNN

```python
class DepthwiseSeparableConv(nn.Module):
    """
    Convolution s√©parable en profondeur
    
    R√©duit les param√®tres de K¬≤ * C_in * C_out √† K¬≤ * C_in + C_in * C_out
    """
    
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):
        super().__init__()
        
        # Convolution depthwise (un filtre par canal)
        self.depthwise = nn.Conv2d(
            in_channels, in_channels, kernel_size,
            stride=stride, padding=padding, groups=in_channels, bias=False
        )
        
        # Convolution pointwise (1x1)
        self.pointwise = nn.Conv2d(in_channels, out_channels, 1, bias=False)
        
        self.bn = nn.BatchNorm2d(out_channels)
        
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        x = self.bn(x)
        return F.relu(x)
    
    def compression_ratio(self, standard_params):
        """Compare avec une convolution standard"""
        my_params = sum(p.numel() for p in self.parameters())
        return standard_params / my_params

# Comparaison
in_ch, out_ch = 64, 128
standard_conv = nn.Conv2d(in_ch, out_ch, 3, padding=1)
separable_conv = DepthwiseSeparableConv(in_ch, out_ch)

print(f"Conv standard: {sum(p.numel() for p in standard_conv.parameters()):,} params")
print(f"Conv s√©parable: {sum(p.numel() for p in separable_conv.parameters()):,} params")
print(f"Ratio: {sum(p.numel() for p in standard_conv.parameters()) / sum(p.numel() for p in separable_conv.parameters()):.2f}x")
```

---

## Exercices

### Exercice 3.2.1
Calculez le nombre de param√®tres et de FLOPs pour une couche Conv2d(64, 128, 3) appliqu√©e √† une entr√©e de taille (1, 64, 32, 32).

### Exercice 3.2.2
Impl√©mentez une fonction qui convertit toutes les convolutions d'un mod√®le en convolutions s√©parables en profondeur.

### Exercice 3.2.3
Cr√©ez un CNN pour classifier des images de traces de particules (hits dans le d√©tecteur de traces).

---

## Points Cl√©s √† Retenir

> üìå **Les CNN exploitent la structure spatiale via des connexions locales et le partage de poids**

> üìå **Le nombre de param√®tres est domin√© par les couches fully-connected**

> üìå **Les convolutions s√©parables r√©duisent les param√®tres d'un facteur ~8-9x**

> üìå **Les connexions r√©siduelles permettent d'entra√Æner des r√©seaux tr√®s profonds**

---

## R√©f√©rences

1. LeCun, Y. et al. "Gradient-based learning applied to document recognition." Proc. IEEE, 1998
2. Simonyan, K., Zisserman, A. "Very Deep Convolutional Networks." ICLR, 2015
3. He, K. et al. "Deep Residual Learning for Image Recognition." CVPR, 2016
4. Howard, A. et al. "MobileNets: Efficient Convolutional Neural Networks." arXiv, 2017

---

*Section suivante : [3.3 R√©seaux R√©currents et Transformers](./03_03_RNN_Transformers.md)*

