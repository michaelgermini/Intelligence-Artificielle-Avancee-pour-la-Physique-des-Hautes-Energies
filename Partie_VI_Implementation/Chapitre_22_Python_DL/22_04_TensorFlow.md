# 22.4 TensorFlow/Keras - Fondamentaux

---

## Introduction

**TensorFlow** est un framework de deep learning dÃ©veloppÃ© par Google, particuliÃ¨rement adaptÃ© pour la production et le dÃ©ploiement. **Keras** fournit une API haut niveau qui simplifie la construction et l'entraÃ®nement de modÃ¨les. Cette section prÃ©sente les fondamentaux de TensorFlow et Keras.

---

## Installation et Configuration

### Setup

```python
import tensorflow as tf

print(f"TensorFlow version: {tf.__version__}")
print(f"GPU available: {tf.config.list_physical_devices('GPU')}")

# VÃ©rifier GPU
if tf.config.list_physical_devices('GPU'):
    print("GPU is available")
    gpu = tf.config.list_physical_devices('GPU')[0]
    print(f"GPU: {gpu}")
```

---

## Tenseurs TensorFlow

### CrÃ©ation et OpÃ©rations

```python
# CrÃ©ation de tenseurs
t1 = tf.constant([[1, 2], [3, 4]])
t2 = tf.constant([[5, 6], [7, 8]])

# OpÃ©rations
sum_t = tf.add(t1, t2)  # ou t1 + t2
prod_t = tf.multiply(t1, t2)  # ou t1 * t2
matmul = tf.matmul(t1, t2)  # ou t1 @ t2

# Variables (modifiables)
var = tf.Variable(initial_value=[[1.0, 2.0], [3.0, 4.0]])
var.assign([[5.0, 6.0], [7.0, 8.0]])  # Modifier valeur

# Tensors avec gradients
x = tf.Variable(2.0)
with tf.GradientTape() as tape:
    y = x ** 2
grad = tape.gradient(y, x)
print(f"dy/dx = {grad.numpy()}")  # 4.0
```

---

## Keras: API SimplifiÃ©e

### ModÃ¨le SÃ©quentiel

```python
from tensorflow import keras
from tensorflow.keras import layers

# ModÃ¨le sÃ©quentiel (le plus simple)
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(10,)),
    layers.Dropout(0.2),
    layers.Dense(32, activation='relu'),
    layers.Dense(3, activation='softmax')
])

# Compiler modÃ¨le
model.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# Afficher architecture
model.summary()
```

---

## API Fonctionnelle

### ModÃ¨les Plus Complexes

```python
# API fonctionnelle pour modÃ¨les non-sÃ©quentiels
inputs = keras.Input(shape=(10,))
x = layers.Dense(64, activation='relu')(inputs)
x = layers.Dropout(0.2)(x)
x = layers.Dense(32, activation='relu')(x)
outputs = layers.Dense(3, activation='softmax')(x)

model = keras.Model(inputs=inputs, outputs=outputs)
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)
```

---

## EntraÃ®nement

### Fit et Callbacks

```python
# DonnÃ©es simulÃ©es
import numpy as np

X_train = np.random.randn(1000, 10)
y_train = np.random.randint(0, 3, (1000,))
X_val = np.random.randn(200, 10)
y_val = np.random.randint(0, 3, (200,))

# EntraÃ®nement
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=10,
    validation_data=(X_val, y_val),
    callbacks=[
        keras.callbacks.EarlyStopping(patience=3),
        keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),
        keras.callbacks.ReduceLROnPlateau(patience=2)
    ]
)

# Ã‰valuation
test_loss, test_acc = model.evaluate(X_val, y_val)
print(f"Test accuracy: {test_acc:.4f}")
```

---

## Callbacks

### Utilitaires d'EntraÃ®nement

```python
callbacks = [
    # Early stopping
    keras.callbacks.EarlyStopping(
        monitor='val_loss',
        patience=5,
        restore_best_weights=True
    ),
    
    # Save best model
    keras.callbacks.ModelCheckpoint(
        'checkpoints/best_model.h5',
        monitor='val_loss',
        save_best_only=True
    ),
    
    # Learning rate reduction
    keras.callbacks.ReduceLROnPlateau(
        monitor='val_loss',
        factor=0.5,
        patience=3
    ),
    
    # TensorBoard
    keras.callbacks.TensorBoard(
        log_dir='./logs',
        histogram_freq=1
    )
]
```

---

## Exemple Complet

### Pipeline EntraÃ®nement

```python
# 1. PrÃ©parer donnÃ©es
X_train = np.random.randn(1000, 10).astype(np.float32)
y_train = np.random.randint(0, 3, (1000,)).astype(np.int32)

# 2. CrÃ©er modÃ¨le
model = keras.Sequential([
    layers.Dense(64, activation='relu', input_shape=(10,)),
    layers.BatchNormalization(),
    layers.Dropout(0.3),
    layers.Dense(32, activation='relu'),
    layers.Dense(3, activation='softmax')
])

# 3. Compiler
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

# 4. EntraÃ®ner
history = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=20,
    validation_split=0.2,
    verbose=1
)

# 5. PrÃ©dictions
predictions = model.predict(X_train[:5])
print(f"Predictions shape: {predictions.shape}")
```

---

## Exercices

### Exercice 22.4.1
CrÃ©ez un modÃ¨le Keras pour classification avec 3 couches cachÃ©es et entraÃ®nez-le.

### Exercice 22.4.2
ImplÃ©mentez un modÃ¨le avec API fonctionnelle Keras qui a deux branches sÃ©parÃ©es.

### Exercice 22.4.3
Configurez des callbacks (early stopping, model checkpoint) et observez leur effet.

---

## Points ClÃ©s Ã  Retenir

> ğŸ“Œ **TensorFlow offre framework complet pour production**

> ğŸ“Œ **Keras simplifie crÃ©ation et entraÃ®nement modÃ¨les**

> ğŸ“Œ **API fonctionnelle permet modÃ¨les complexes (branches, skip connections)**

> ğŸ“Œ **Callbacks automatisent tÃ¢ches communes (early stopping, saving)**

> ğŸ“Œ **TensorFlow/Keras excellent pour dÃ©ploiement production**

---

*Section prÃ©cÃ©dente : [22.3.3 DataLoaders](./22_03_03_DataLoaders.md) | Section suivante : [22.5 Bonnes Pratiques](./22_05_Bonnes_Pratiques.md)*

