# 20.5 Quantification de l'Incertitude

---

## Introduction

La **quantification de l'incertitude** est cruciale pour la dÃ©tection d'anomalies en physique des hautes Ã©nergies. Il est essentiel de distinguer les vraies anomalies des Ã©vÃ©nements qui semblent anormaux simplement Ã  cause d'incertitudes statistiques ou systÃ©matiques. De plus, l'incertitude permet d'Ã©valuer la confiance dans les prÃ©dictions et de guider les dÃ©cisions.

Cette section prÃ©sente les mÃ©thodes pour quantifier l'incertitude dans les modÃ¨les de dÃ©tection d'anomalies, incluant les approches bayÃ©siennes, ensemblistes, et basÃ©es sur la calibration.

---

## Types d'Incertitude

### Ã‰pistÃ©mique vs AlÃ©atoire

```python
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import Dict, Tuple

class UncertaintyTypes:
    """
    Types d'incertitude
    """
    
    def __init__(self):
        self.uncertainty_types = {
            'epistemic': {
                'description': 'Incertitude sur le modÃ¨le (rÃ©ductible avec plus de donnÃ©es)',
                'also_known_as': 'Incertitude de modÃ¨le',
                'sources': [
                    'ParamÃ¨tres du modÃ¨le incertains',
                    'Manque de donnÃ©es dans certaines rÃ©gions',
                    'Limites du modÃ¨le'
                ],
                'quantification': ['Bayesian neural networks', 'Dropout', 'Ensembles'],
                'reduction': 'Plus de donnÃ©es, meilleur modÃ¨le'
            },
            'aleatoric': {
                'description': 'Incertitude intrinsÃ¨que aux donnÃ©es (irrÃ©ductible)',
                'also_known_as': 'Incertitude de donnÃ©es',
                'sources': [
                    'Bruit de mesure',
                    'VariabilitÃ© naturelle',
                    'RÃ©solution dÃ©tecteur'
                ],
                'quantification': ['Output variance', 'Heteroscedastic models'],
                'reduction': 'Ne peut pas Ãªtre rÃ©duite, seulement quantifiÃ©e'
            },
            'systematic': {
                'description': 'Incertitudes systÃ©matiques expÃ©rimentales',
                'also_known_as': 'Incertitudes systÃ©matiques',
                'sources': [
                    'Calibration dÃ©tecteurs',
                    'ModÃ©lisation backgrounds',
                    'Acceptance et efficacitÃ©'
                ],
                'quantification': ['Nuisance parameters', 'Systematic variations'],
                'reduction': 'AmÃ©lioration mesures, meilleure comprÃ©hension'
            }
        }
    
    def display_types(self):
        """Affiche les types"""
        print("\n" + "="*70)
        print("Types d'Incertitude")
        print("="*70)
        
        for unc_type, info in self.uncertainty_types.items():
            print(f"\n{unc_type.replace('_', ' ').title()} ({info['also_known_as']}):")
            print(f"  Description: {info['description']}")
            print(f"  Sources:")
            for source in info['sources']:
                print(f"    â€¢ {source}")
            print(f"  Quantification: {', '.join(info['quantification'])}")
            print(f"  RÃ©duction: {info['reduction']}")

unc_types = UncertaintyTypes()
unc_types.display_types()
```

---

## Incertitude Ã‰pistÃ©mique: Bayesian Neural Networks

### RÃ©seaux BayÃ©siens

```python
class BayesianLinear(nn.Module):
    """
    Couche linÃ©aire bayÃ©sienne
    
    Poids suivent distributions au lieu de valeurs fixes
    """
    
    def __init__(self, in_features, out_features, prior_std=1.0):
        super().__init__()
        
        # Moyennes des poids (paramÃ¨tres Ã  apprendre)
        self.weight_mu = nn.Parameter(torch.randn(out_features, in_features))
        self.bias_mu = nn.Parameter(torch.randn(out_features))
        
        # Log-variance des poids (paramÃ¨tres Ã  apprendre)
        self.weight_logvar = nn.Parameter(torch.randn(out_features, in_features) * 0.1)
        self.bias_logvar = nn.Parameter(torch.randn(out_features) * 0.1)
        
        self.prior_std = prior_std
    
    def forward(self, x, sample=True):
        """
        Forward pass avec Ã©chantillonnage de poids
        
        Args:
            sample: Si True, Ã©chantillonne poids depuis distribution
        """
        if sample:
            # Ã‰chantillonner poids depuis distributions
            weight_std = torch.exp(0.5 * self.weight_logvar)
            weight_eps = torch.randn_like(weight_std)
            weight = self.weight_mu + weight_std * weight_eps
            
            bias_std = torch.exp(0.5 * self.bias_logvar)
            bias_eps = torch.randn_like(bias_std)
            bias = self.bias_mu + bias_std * bias_eps
        else:
            # Utiliser moyennes
            weight = self.weight_mu
            bias = self.bias_mu
        
        return F.linear(x, weight, bias)
    
    def kl_divergence(self):
        """
        Calcule KL divergence entre posterior et prior
        
        Pour variational inference
        """
        # Prior: N(0, prior_stdÂ²)
        # Posterior: N(mu, exp(logvar))
        
        weight_kl = -0.5 * torch.sum(
            1 + self.weight_logvar - 
            (self.weight_mu / self.prior_std)**2 - 
            torch.exp(self.weight_logvar) / (self.prior_std**2)
        )
        
        bias_kl = -0.5 * torch.sum(
            1 + self.bias_logvar - 
            (self.bias_mu / self.prior_std)**2 - 
            torch.exp(self.bias_logvar) / (self.prior_std**2)
        )
        
        return weight_kl + bias_kl

class BayesianAutoencoder(nn.Module):
    """
    Autoencodeur bayÃ©sien pour quantification incertitude
    """
    
    def __init__(self, input_dim=100, latent_dim=20, hidden_dim=64):
        super().__init__()
        
        # Encodeur bayÃ©sien
        self.encoder_fc1 = BayesianLinear(input_dim, hidden_dim)
        self.encoder_fc2 = BayesianLinear(hidden_dim, latent_dim)
        
        # DÃ©codeur bayÃ©sien
        self.decoder_fc1 = BayesianLinear(latent_dim, hidden_dim)
        self.decoder_fc2 = BayesianLinear(hidden_dim, input_dim)
        
        self.activation = nn.ReLU()
    
    def forward(self, x, sample=True):
        """Forward avec Ã©chantillonnage"""
        # Encodeur
        h = self.activation(self.encoder_fc1(x, sample=sample))
        latent = self.encoder_fc2(h, sample=sample)
        
        # DÃ©codeur
        h = self.activation(self.decoder_fc1(latent, sample=sample))
        reconstructed = self.decoder_fc2(h, sample=sample)
        
        return reconstructed
    
    def compute_kl_loss(self):
        """Calcule KL divergence totale"""
        kl = (self.encoder_fc1.kl_divergence() + 
              self.encoder_fc2.kl_divergence() +
              self.decoder_fc1.kl_divergence() +
              self.decoder_fc2.kl_divergence())
        return kl
    
    def predict_with_uncertainty(self, x, n_samples=100):
        """
        PrÃ©dit avec quantification d'incertitude
        
        Ã‰chantillonne plusieurs fois pour estimer incertitude
        """
        predictions = []
        
        for _ in range(n_samples):
            pred = self.forward(x, sample=True)
            predictions.append(pred)
        
        predictions = torch.stack(predictions)
        
        # Statistiques
        mean_pred = predictions.mean(dim=0)
        std_pred = predictions.std(dim=0)
        
        # Incertitude Ã©pistÃ©mique = variance des prÃ©dictions
        epistemic_uncertainty = std_pred
        
        return {
            'mean': mean_pred,
            'std': std_pred,
            'epistemic_uncertainty': epistemic_uncertainty
        }

bayesian_ae = BayesianAutoencoder(input_dim=50, latent_dim=10)

print(f"\nBayesian Autoencoder:")
print(f"  ParamÃ¨tres: {sum(p.numel() for p in bayesian_ae.parameters()):,}")
```

---

## Incertitude via Dropout

### Monte Carlo Dropout

```python
class DropoutUncertainty:
    """
    Quantification incertitude via Monte Carlo Dropout
    """
    
    def __init__(self, model, dropout_rate=0.5):
        """
        Args:
            model: ModÃ¨le avec couches dropout
            dropout_rate: Taux de dropout
        """
        self.model = model
        self.dropout_rate = dropout_rate
        
        # S'assurer que dropout est activÃ© mÃªme en eval
        self._enable_dropout()
    
    def _enable_dropout(self):
        """Active dropout mÃªme en mode eval"""
        for module in self.model.modules():
            if isinstance(module, nn.Dropout):
                module.train()  # Force mode training pour garder dropout
    
    def predict_with_uncertainty(self, x, n_samples=100):
        """
        PrÃ©dit avec incertitude via MC Dropout
        
        Ã‰chantillonne plusieurs fois avec dropout activÃ©
        """
        self.model.eval()
        self._enable_dropout()  # Important: garder dropout
        
        predictions = []
        
        with torch.no_grad():
            for _ in range(n_samples):
                pred = self.model(x)
                predictions.append(pred)
        
        predictions = torch.stack(predictions)
        
        mean_pred = predictions.mean(dim=0)
        std_pred = predictions.std(dim=0)
        
        return {
            'mean': mean_pred,
            'std': std_pred,
            'uncertainty': std_pred
        }

# Exemple avec autoencodeur avec dropout
dropout_ae = nn.Sequential(
    nn.Linear(50, 64),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(64, 10),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(10, 64),
    nn.ReLU(),
    nn.Dropout(0.5),
    nn.Linear(64, 50)
)

dropout_uncertainty = DropoutUncertainty(dropout_ae, dropout_rate=0.5)
```

---

## Ensembles pour Incertitude

### Ensembles de ModÃ¨les

```python
class EnsembleUncertainty:
    """
    Quantification incertitude via ensembles de modÃ¨les
    """
    
    def __init__(self, models: List[nn.Module]):
        """
        Args:
            models: Liste de modÃ¨les entraÃ®nÃ©s diffÃ©remment
        """
        self.models = models
    
    def predict_with_uncertainty(self, x):
        """
        PrÃ©dit avec incertitude via variance d'ensemble
        """
        predictions = []
        
        for model in self.models:
            with torch.no_grad():
                pred = model(x)
                predictions.append(pred)
        
        predictions = torch.stack(predictions)
        
        mean_pred = predictions.mean(dim=0)
        std_pred = predictions.std(dim=0)
        
        return {
            'mean': mean_pred,
            'std': std_pred,
            'uncertainty': std_pred,
            'predictions': predictions
        }
    
    def compute_anomaly_score_with_uncertainty(self, x):
        """
        Score d'anomalie avec incertitude
        
        Score = erreur reconstruction + pÃ©nalitÃ© incertitude
        """
        results = self.predict_with_uncertainty(x)
        
        # Erreur de reconstruction moyenne
        mean_error = torch.mean((x - results['mean'])**2, dim=1)
        
        # Incertitude moyenne
        mean_uncertainty = torch.mean(results['uncertainty'], dim=1)
        
        # Score combinÃ©: Ã©vÃ©nements avec haute erreur ET haute incertitude = moins confiant
        # Score Ã©levÃ© si erreur haute mais incertitude basse (confiant dans anomalie)
        anomaly_score = mean_error / (mean_uncertainty + 1e-6)
        
        return {
            'anomaly_score': anomaly_score,
            'reconstruction_error': mean_error,
            'uncertainty': mean_uncertainty
        }

# CrÃ©er ensemble
ensemble_models = [
    BasicAutoencoder(input_dim=50, latent_dim=10) for _ in range(5)
]

ensemble = EnsembleUncertainty(ensemble_models)

print(f"\nEnsemble Uncertainty:")
print(f"  Nombre de modÃ¨les: {len(ensemble.models)}")
```

---

## Incertitude AlÃ©atoire: ModÃ¨les HÃ©tÃ©roscÃ©dastiques

### PrÃ©diction de Variance

```python
class HeteroscedasticAutoencoder(nn.Module):
    """
    Autoencodeur hÃ©tÃ©roscÃ©dastique
    
    PrÃ©dit Ã  la fois moyenne et variance (incertitude alÃ©atoire)
    """
    
    def __init__(self, input_dim=100, latent_dim=20, hidden_dim=64):
        super().__init__()
        
        # Encodeur
        self.encoder = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, latent_dim)
        )
        
        # DÃ©codeur pour moyenne
        self.decoder_mean = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )
        
        # DÃ©codeur pour variance (log-variance pour positivitÃ©)
        self.decoder_logvar = nn.Sequential(
            nn.Linear(latent_dim, hidden_dim),
            nn.ReLU(),
            nn.Linear(hidden_dim, input_dim)
        )
    
    def forward(self, x):
        """Forward pass"""
        latent = self.encoder(x)
        
        mean = self.decoder_mean(latent)
        logvar = self.decoder_logvar(latent)
        
        return mean, logvar
    
    def compute_loss(self, x):
        """
        Loss pour modÃ¨le hÃ©tÃ©roscÃ©dastique
        
        Log-likelihood avec variance prÃ©dite
        """
        mean, logvar = self.forward(x)
        
        # Variance prÃ©dite
        var = torch.exp(logvar)
        
        # Negative log-likelihood (gaussien)
        nll = 0.5 * torch.sum(
            torch.log(2 * np.pi * var) + (x - mean)**2 / var,
            dim=1
        ).mean()
        
        return nll
    
    def predict_with_uncertainty(self, x):
        """
        PrÃ©dit avec incertitude alÃ©atoire
        """
        with torch.no_grad():
            mean, logvar = self.forward(x)
            std = torch.exp(0.5 * logvar)
            
            return {
                'mean': mean,
                'std': std,
                'variance': torch.exp(logvar),
                'aleatoric_uncertainty': std
            }

hetero_ae = HeteroscedasticAutoencoder(input_dim=50, latent_dim=10)

print(f"\nHeteroscedastic Autoencoder:")
print(f"  ParamÃ¨tres: {sum(p.numel() for p in hetero_ae.parameters()):,}")
```

---

## Application Ã  DÃ©tection d'Anomalies

### Utilisation de l'Incertitude

```python
class UncertaintyAwareAnomalyDetection:
    """
    DÃ©tection d'anomalies prenant en compte incertitude
    """
    
    def __init__(self, model, uncertainty_quantifier):
        """
        Args:
            model: ModÃ¨le de dÃ©tection d'anomalies
            uncertainty_quantifier: MÃ©thode pour quantifier incertitude
        """
        self.model = model
        self.uncertainty_quantifier = uncertainty_quantifier
    
    def detect_anomalies_with_confidence(self, x, 
                                        error_threshold: float,
                                        uncertainty_threshold: float):
        """
        DÃ©tecte anomalies avec seuils sur erreur ET incertitude
        
        Anomalie confiante = haute erreur + basse incertitude
        """
        # Calculer erreur de reconstruction
        with torch.no_grad():
            reconstructed = self.model(x)
            error = torch.mean((x - reconstructed)**2, dim=1)
        
        # Calculer incertitude
        unc_result = self.uncertainty_quantifier.predict_with_uncertainty(x)
        uncertainty = torch.mean(unc_result['uncertainty'], dim=1)
        
        # DÃ©cisions
        high_error = error > error_threshold
        low_uncertainty = uncertainty < uncertainty_threshold
        
        # Anomalies confiantes
        confident_anomalies = high_error & low_uncertainty
        
        # Ã‰vÃ©nements avec haute incertitude (Ã  examiner)
        high_uncertainty_events = uncertainty > uncertainty_threshold
        
        return {
            'anomaly_indices': torch.where(confident_anomalies)[0],
            'high_uncertainty_indices': torch.where(high_uncertainty_events)[0],
            'error': error,
            'uncertainty': uncertainty,
            'confidence': 1.0 / (uncertainty + 1e-6)  # Plus incertitude basse = plus confiant
        }
    
    def compute_calibrated_threshold(self, validation_data, target_fpr=0.05):
        """
        Calcule seuil calibrÃ© tenant compte incertitude
        
        Ajuste seuil selon incertitude pour maintenir FPR constant
        """
        # Calculer erreurs et incertitudes
        with torch.no_grad():
            reconstructed = self.model(validation_data)
            errors = torch.mean((validation_data - reconstructed)**2, dim=1)
        
        unc_result = self.uncertainty_quantifier.predict_with_uncertainty(validation_data)
        uncertainties = torch.mean(unc_result['uncertainty'], dim=1)
        
        # Score ajustÃ© par incertitude
        # Plus incertitude Ã©levÃ©e = seuil plus Ã©levÃ© (moins sensible)
        adjusted_scores = errors / (uncertainties + 1e-6)
        
        # Trouver seuil pour FPR cible
        threshold = np.percentile(adjusted_scores.numpy(), (1 - target_fpr) * 100)
        
        return threshold

# Application
bayesian_uncertainty = lambda model, x: model.predict_with_uncertainty(x, n_samples=50)
unc_aware_detector = UncertaintyAwareAnomalyDetection(bayesian_ae, bayesian_uncertainty)
```

---

## Exercices

### Exercice 20.5.1
ImplÃ©mentez un autoencodeur bayÃ©sien complet avec variational inference et comparez incertitude Ã©pistÃ©mique vs alÃ©atoire.

### Exercice 20.5.2
Utilisez Monte Carlo Dropout pour quantifier incertitude dans un autoencodeur et analysez l'impact du taux de dropout.

### Exercice 20.5.3
CrÃ©ez un systÃ¨me de dÃ©tection d'anomalies qui utilise incertitude pour filtrer les anomalies peu confiantes.

### Exercice 20.5.4
Comparez diffÃ©rentes mÃ©thodes de quantification d'incertitude (Bayesian, Dropout, Ensemble) sur mÃªme modÃ¨le.

---

## Points ClÃ©s Ã  Retenir

> ğŸ“Œ **L'incertitude Ã©pistÃ©mique est rÃ©ductible avec plus de donnÃ©es**

> ğŸ“Œ **L'incertitude alÃ©atoire est intrinsÃ¨que et irrÃ©ductible**

> ğŸ“Œ **Les Bayesian Neural Networks quantifient incertitude Ã©pistÃ©mique**

> ğŸ“Œ **Monte Carlo Dropout est simple et efficace pour incertitude**

> ğŸ“Œ **Les ensembles de modÃ¨les donnent estimation robuste d'incertitude**

> ğŸ“Œ **L'utilisation d'incertitude amÃ©liore fiabilitÃ© dÃ©tection d'anomalies**

---

*Section prÃ©cÃ©dente : [20.4 RÃ©seaux de Tenseurs](./20_04_Tenseurs.md)*

